{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikeras Keras regressor integration\n",
    "\n",
    "The integration of KerasRegressor in pipeline is limited. To use full keras capabilities, you may need to modify the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 2151) (272,) (152, 2151) (152,)\n"
     ]
    }
   ],
   "source": [
    "# Standard loading and preprocessing code\n",
    "\n",
    "from pinard import nirs_set as n_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Init basic random\n",
    "rd_seed = 42\n",
    "np.random.seed(rd_seed)\n",
    "tf.random.set_seed(rd_seed)\n",
    "random.seed(rd_seed)\n",
    "# tf.config.experimental.enable_op_determinism()\n",
    "# tf.config.experimental.disable_op_determinism()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a set named data\n",
    "n = n_set.NIRS_Set('data')\n",
    "\n",
    "# Load csv data and split into train and test\n",
    "# X, y = n.load('Xcal.csv', 'Ycal.csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rd_seed)\n",
    "\n",
    "\n",
    "# X_train, y_train = n.load('Xcal (7).csv', 'Ycal (7).csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "# X_test, y_test = n.load('Xval (7).csv', 'Yval (7).csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "\n",
    "# X_train, y_train = n.load('Xcal (8).csv', 'Ycal (8).csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "# X_test, y_test = n.load('Xval (8).csv', 'Yval (8).csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "\n",
    "# X_train, y_train = n.load('gilles/Xcal.csv', 'gilles/Ycal.csv', y_cols=0)\n",
    "# X_test, y_test = n.load('gilles/Xval.csv', 'gilles/Yval.csv', y_cols=0)\n",
    "\n",
    "# path = \"benchmark/regression/LUCAS_SOCgrassland_4096_Nocita_RMSE7.2\"\n",
    "path = \"benchmark/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\"\n",
    "X_train, y_train = n.load(path + '/Xcal.csv', path + '/Ycal.csv', y_cols=0, x_hdr=0, y_hdr=0)\n",
    "X_test, y_test = n.load(path + '/Xval.csv', path + '/Yval.csv', y_cols=0, x_hdr=0, y_hdr=0)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "from pinard import preprocessor as pp\n",
    "from sklearn.pipeline import Pipeline\n",
    "    # \"Baseline\", \n",
    "    # \"StandardNormalVariate\", ## SAME as STANDARDSCALER\n",
    "    # \"RobustNormalVariate\", ## SAME as ROBUSTSCALER\n",
    "    # \"SavitzkyGolay\",\n",
    "    # \"Normalize\",\n",
    "    # \"Detrend\",\n",
    "    # \"MultiplicativeScatterCorrection\",\n",
    "    # \"Derivate\",\n",
    "    # \"Gaussian\",\n",
    "    # \"Wavelet\",\n",
    "    # \"SimpleScale\",\n",
    "\n",
    "\n",
    "### Declare preprocessing pipeline components\n",
    "preprocessing = [   ('id', pp.IdentityTransformer()),\n",
    "                    ('baseline', pp.StandardNormalVariate()),\n",
    "                    ('savgol', pp.SavitzkyGolay()),\n",
    "                    ('gaussian1', pp.Gaussian(order = 1, sigma = 2)),\n",
    "                    ('gaussian2', pp.Gaussian(order = 2, sigma = 1)),\n",
    "                    ('haar', pp.Wavelet('haar')),\n",
    "                    ('coif3', pp.Wavelet('coif3')),\n",
    "                    ('detrend', pp.Detrend()),\n",
    "                    ('msc', pp.MultiplicativeScatterCorrection(scale=False)),\n",
    "                    ('dv1', pp.Derivate(1,1)),\n",
    "                    ('dv2', pp.Derivate(2,1)),\n",
    "                    ('dv3', pp.Derivate(2,2)),\n",
    "                    \n",
    "                    ('baseline*savgol', Pipeline([('_sg1',pp.StandardNormalVariate()),('_sg2',pp.SavitzkyGolay())])),\n",
    "                    ('baseline*gaussian1', Pipeline([('_sg1',pp.StandardNormalVariate()),('g2', pp.Gaussian(order = 1, sigma = 2) )])),\n",
    "                    ('baseline*gaussian2', Pipeline([('_sg1',pp.StandardNormalVariate()),('g2', pp.Gaussian(order = 2, sigma = 1) )])),\n",
    "                    ('baseline*haar', Pipeline([('_sg1',pp.StandardNormalVariate()),('_sg2',pp.Wavelet('haar'))])),\n",
    "                    \n",
    "                    # ('savgol*savgol', Pipeline([('_sg1',pp.SavitzkyGolay()),('_sg2',pp.SavitzkyGolay())])),\n",
    "                    # ('savgol*baseline', Pipeline([('_sg1',pp.SavitzkyGolay()),('_sg2',pp.StandardNormalVariate())])),\n",
    "                    ('savgol*gaussian1', Pipeline([('_sg1',pp.SavitzkyGolay()),('g2', pp.Gaussian(order = 1, sigma = 2) )])),\n",
    "                    ('savgol*gaussian2', Pipeline([('_sg1',pp.SavitzkyGolay()),('g2', pp.Gaussian(order = 2, sigma = 1) )])),\n",
    "                    # ('savgol*haar', Pipeline([('_sg1',pp.SavitzkyGolay()), ('haar', pp.Wavelet('haar'))])),\n",
    "                    # ('gaussian1*savgol', Pipeline([('_g1',pp.Gaussian(order = 1, sigma = 2)),('_sg3',pp.SavitzkyGolay())])),\n",
    "                    ('gaussian2*savgol', Pipeline([('_g2',pp.Gaussian(order = 1, sigma = 2)),('_sg4',pp.SavitzkyGolay())])),\n",
    "                    # ('haar*savgol', Pipeline([('_haar2',pp.Wavelet('haar')),('_sg5',pp.SavitzkyGolay())])),\n",
    "                    # ('haar*gaussian1', Pipeline([('_haar2',pp.Wavelet('haar')), ('g2', pp.Gaussian(order = 1, sigma = 2)) ])),\n",
    "                    ('haar*gaussian2', Pipeline([('_haar2',pp.Wavelet('haar')), ('g2', pp.Gaussian(order = 2, sigma = 1)) ])),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex pipeline\n",
    "\n",
    "In the following example we will declare a custom callback, un custom optimizer and we will use test data as validation metrics for the keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Adam optimizer with Cyclic Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow_addons.optimizers import CyclicalLearningRate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 192\n",
    "EPOCHS = 10000\n",
    "# MIN_LR = 5e-7\n",
    "# MAX_LR = 1e-3\n",
    "\n",
    "MIN_LR = 2e-5\n",
    "MAX_LR = 9e-3\n",
    "CYCLE_LENGTH = 1024\n",
    "\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "\n",
    "# Define the learning rate cycle properties\n",
    "clr = CyclicalLearningRate(\n",
    "    initial_learning_rate=MIN_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size= CYCLE_LENGTH * steps_per_epoch\n",
    ")\n",
    "\n",
    "optimizer = Adam(clr)\n",
    "# optimizer = Adadelta(clr)\n",
    "\n",
    "# Display learning rate evolution\n",
    "epochs = np.arange(0, EPOCHS)\n",
    "lr = clr(steps_per_epoch * epochs)\n",
    "plt.plot(epochs, lr)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,6)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom callback\n",
    "\n",
    "We define a custom callback that store the current best model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# custom Keras Callback that store \n",
    "class Auto_Save(Callback):\n",
    "    best_weights = []\n",
    "    def __init__(self):\n",
    "        super(Auto_Save, self).__init__()\n",
    "        self.best = np.Inf\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_loss = logs.get('val_loss')\n",
    "        if np.less(current_loss, self.best):\n",
    "            self.best = current_loss            \n",
    "            Auto_Save.best_weights = self.model.get_weights()\n",
    "            print(\"Best so far >\", self.best)\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.params['verbose'] == 2:\n",
    "            print('\\nSaved best {0:6.4f}\\n'.format(self.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom callback to display Learning rate during training\n",
    "\n",
    "We define a custom callback to display the evolution of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Print_LR(Callback):    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        iteration = self.model.optimizer.iterations.numpy()\n",
    "        # lr = clr(iteration).numpy()\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if self.params['verbose'] == 2:\n",
    "            print(\"Iteration {} - Learning rate: {}\".format(iteration, lr) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacon VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate,GlobalAveragePooling1D, Conv1D, Activation, SpatialDropout1D,SeparableConv1D,Flatten, Dropout, Input, MaxPooling1D, DepthwiseConv1D, BatchNormalization, AveragePooling1D\n",
    "from typing import Dict, Iterable, Any\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "\n",
    "def conv1D_block(model, filters):\n",
    "    # model.add(SpatialDropout1D(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=filters, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=3, padding=\"same\"))\n",
    "    model.add(MaxPooling1D(pool_size=4,strides=2))\n",
    "\n",
    "def depthconv1D_block(model, filters):\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv1D(kernel_size=3, depth_multiplier=filters, padding=\"same\", activation='swish'))\n",
    "    model.add(DepthwiseConv1D(kernel_size=3, depth_multiplier=filters, padding=\"same\", activation='swish'))\n",
    "    model.add(AveragePooling1D(pool_size=4,strides=2))\n",
    "    \n",
    "def sepconv1D_block(model, filters):\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(SeparableConv1D(filters, kernel_size=3, depth_multiplier=1, padding=\"same\", activation='swish'))\n",
    "    model.add(SeparableConv1D(filters, kernel_size=3, depth_multiplier=1, padding=\"same\", activation='swish'))\n",
    "    model.add(MaxPooling1D(pool_size=5,strides=3))\n",
    "\n",
    "def keras_model(meta: Dict[str, Any]):\n",
    "    input_shape = meta[\"X_shape_\"][1:]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    # depthconv1D_block(model, 1)\n",
    "    depthconv1D_block(model, 2)\n",
    "    depthconv1D_block(model, 4)\n",
    "    depthconv1D_block(model, 4)\n",
    "    # model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "    model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "    sepconv1D_block(model, 128)\n",
    "    # conv1D_block(model, 128)\n",
    "    # conv1D_block(model, 16)\n",
    "    # conv1D_block(model, 256)\n",
    "    # model.add(MaxPooling1D(pool_size=11,strides=5))\n",
    "    # depthconv1D_block(model, 256)\n",
    "    # model.add(BatchNormalization())\n",
    "    # depthconv1D_block(model, 128)\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    # we compile the model with the custom Adam optimizer\n",
    "    model.compile(loss = 'mean_squared_error', metrics=['mse'], optimizer = \"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate,GlobalAveragePooling1D, Conv1D, Activation, SpatialDropout1D,SeparableConv1D,Flatten, Dropout, Input, MaxPooling1D, DepthwiseConv1D, BatchNormalization, AveragePooling1D\n",
    "from typing import Dict, Iterable, Any\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "import models\n",
    "\n",
    "# BATCH_SIZE = 128\n",
    "# EPOCHS = 10000\n",
    "# # MIN_LR = 5e-7\n",
    "# # MAX_LR = 1e-3\n",
    "\n",
    "# MIN_LR = 5e-5\n",
    "# MAX_LR = 5e-3\n",
    "# CYCLE_LENGTH = 512\n",
    "\n",
    "def keras_model(meta: Dict[str, Any]):\n",
    "    input_shape = meta[\"X_shape_\"][1:]\n",
    "    # model = models.xception(input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(DepthwiseConv1D(kernel_size=7, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(DepthwiseConv1D(kernel_size=7, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv1D(kernel_size=5, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(DepthwiseConv1D(kernel_size=5, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv1D(kernel_size=9, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(DepthwiseConv1D(kernel_size=9, padding=\"same\",depth_multiplier=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SeparableConv1D(128, kernel_size=5, depth_multiplier=1, padding=\"same\", activation='relu'))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(MaxPooling1D(pool_size=5,strides=3))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=32, activation=\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    # # optimizer = Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-07)\n",
    "    # model.compile(loss = 'mean_squared_error', metrics=['mse'], optimizer = optimizer)\n",
    "    model.compile(loss = 'mean_squared_error', metrics=['mse'], optimizer = \"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex pipeline\n",
    "\n",
    "In this pipeline we decompose transformers and estimators to be able to use custom validation data in the fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORM\n",
      "ahahah (152, 2151, 20)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " spatial_dropout1d_10 (Spati  (None, 2151, 20)         0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " depthwise_conv1d_30 (Depthw  (None, 2151, 40)         320       \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " depthwise_conv1d_31 (Depthw  (None, 2151, 80)         640       \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " average_pooling1d_10 (Avera  (None, 1075, 80)         0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1075, 80)         320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv1d_32 (Depthw  (None, 1075, 160)        960       \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " depthwise_conv1d_33 (Depthw  (None, 1075, 320)        1920      \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " average_pooling1d_11 (Avera  (None, 537, 320)         0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 537, 320)         1280      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv1d_34 (Depthw  (None, 537, 640)         6400      \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " depthwise_conv1d_35 (Depthw  (None, 537, 1280)        12800     \n",
      " iseConv1D)                                                      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 268, 1280)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 268, 1280)        5120      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " separable_conv1d_5 (Separab  (None, 268, 128)         170368    \n",
      " leConv1D)                                                       \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 268, 32)           12320     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 88, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " spatial_dropout1d_11 (Spati  (None, 88, 32)           0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2816)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               360576    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 577,185\n",
      "Trainable params: 573,825\n",
      "Non-trainable params: 3,360\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "Iteration 5 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 5s - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0276 - val_mse: 0.0276 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "Iteration 10 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0201 - val_mse: 0.0201 - 1s/epoch - 244ms/step\n",
      "Epoch 3/10000\n",
      "Iteration 15 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0237 - val_mse: 0.0237 - 1s/epoch - 236ms/step\n",
      "Epoch 4/10000\n",
      "Iteration 20 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0208 - val_mse: 0.0208 - 1s/epoch - 239ms/step\n",
      "Epoch 5/10000\n",
      "Iteration 25 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0200 - val_mse: 0.0200 - 1s/epoch - 246ms/step\n",
      "Epoch 6/10000\n",
      "Iteration 30 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0203 - val_mse: 0.0203 - 1s/epoch - 238ms/step\n",
      "Epoch 7/10000\n",
      "Iteration 35 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0208 - val_mse: 0.0208 - 1s/epoch - 239ms/step\n",
      "Epoch 8/10000\n",
      "Iteration 40 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0202 - val_mse: 0.0202 - 1s/epoch - 240ms/step\n",
      "Epoch 9/10000\n",
      "Iteration 45 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0204 - val_mse: 0.0204 - 1s/epoch - 237ms/step\n",
      "Epoch 10/10000\n",
      "Iteration 50 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0207 - val_mse: 0.0207 - 1s/epoch - 239ms/step\n",
      "Epoch 11/10000\n",
      "Iteration 55 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0213 - val_mse: 0.0213 - 1s/epoch - 243ms/step\n",
      "Epoch 12/10000\n",
      "Iteration 60 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0209 - val_mse: 0.0209 - 1s/epoch - 236ms/step\n",
      "Epoch 13/10000\n",
      "Iteration 65 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0204 - val_mse: 0.0204 - 1s/epoch - 238ms/step\n",
      "Epoch 14/10000\n",
      "Iteration 70 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0204 - val_mse: 0.0204 - 1s/epoch - 243ms/step\n",
      "Epoch 15/10000\n",
      "Iteration 75 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0212 - val_mse: 0.0212 - 1s/epoch - 243ms/step\n",
      "Epoch 16/10000\n",
      "Iteration 80 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0216 - val_mse: 0.0216 - 1s/epoch - 241ms/step\n",
      "Epoch 17/10000\n",
      "Iteration 85 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0227 - val_mse: 0.0227 - 1s/epoch - 237ms/step\n",
      "Epoch 18/10000\n",
      "Iteration 90 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0233 - val_mse: 0.0233 - 1s/epoch - 246ms/step\n",
      "Epoch 19/10000\n",
      "Iteration 95 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0234 - val_mse: 0.0234 - 1s/epoch - 238ms/step\n",
      "Epoch 20/10000\n",
      "Iteration 100 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0221 - val_mse: 0.0221 - 1s/epoch - 238ms/step\n",
      "Epoch 21/10000\n",
      "Iteration 105 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0214 - val_mse: 0.0214 - 1s/epoch - 236ms/step\n",
      "Epoch 22/10000\n",
      "Iteration 110 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0216 - val_mse: 0.0216 - 1s/epoch - 241ms/step\n",
      "Epoch 23/10000\n",
      "Iteration 115 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0234 - val_mse: 0.0234 - 1s/epoch - 239ms/step\n",
      "Epoch 24/10000\n",
      "Iteration 120 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0218 - val_mse: 0.0218 - 1s/epoch - 236ms/step\n",
      "Epoch 25/10000\n",
      "Iteration 125 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0219 - val_mse: 0.0219 - 1s/epoch - 235ms/step\n",
      "Epoch 26/10000\n",
      "Iteration 130 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0224 - val_mse: 0.0224 - 1s/epoch - 238ms/step\n",
      "Epoch 27/10000\n",
      "Iteration 135 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0257 - val_mse: 0.0257 - 1s/epoch - 240ms/step\n",
      "Epoch 28/10000\n",
      "Iteration 140 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0275 - val_mse: 0.0275 - 1s/epoch - 235ms/step\n",
      "Epoch 29/10000\n",
      "Iteration 145 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0264 - val_mse: 0.0264 - 1s/epoch - 246ms/step\n",
      "Epoch 30/10000\n",
      "Iteration 150 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0254 - val_mse: 0.0254 - 1s/epoch - 232ms/step\n",
      "Epoch 31/10000\n",
      "Iteration 155 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0259 - val_mse: 0.0259 - 1s/epoch - 233ms/step\n",
      "Epoch 32/10000\n",
      "Iteration 160 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0262 - val_mse: 0.0262 - 1s/epoch - 239ms/step\n",
      "Epoch 33/10000\n",
      "Iteration 165 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0258 - val_mse: 0.0258 - 1s/epoch - 238ms/step\n",
      "Epoch 34/10000\n",
      "Iteration 170 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0267 - val_mse: 0.0267 - 1s/epoch - 243ms/step\n",
      "Epoch 35/10000\n",
      "Iteration 175 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0265 - val_mse: 0.0265 - 1s/epoch - 241ms/step\n",
      "Epoch 36/10000\n",
      "Iteration 180 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0266 - val_mse: 0.0266 - 1s/epoch - 235ms/step\n",
      "Epoch 37/10000\n",
      "Iteration 185 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0258 - val_mse: 0.0258 - 1s/epoch - 234ms/step\n",
      "Epoch 38/10000\n",
      "Iteration 190 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0248 - val_mse: 0.0248 - 1s/epoch - 235ms/step\n",
      "Epoch 39/10000\n",
      "Iteration 195 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0247 - val_mse: 0.0247 - 1s/epoch - 235ms/step\n",
      "Epoch 40/10000\n",
      "Iteration 200 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0235 - val_mse: 0.0235 - 1s/epoch - 232ms/step\n",
      "Epoch 41/10000\n",
      "Iteration 205 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0239 - val_mse: 0.0239 - 1s/epoch - 227ms/step\n",
      "Epoch 42/10000\n",
      "Iteration 210 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0232 - val_mse: 0.0232 - 1s/epoch - 240ms/step\n",
      "Epoch 43/10000\n",
      "Iteration 215 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0222 - val_mse: 0.0222 - 1s/epoch - 231ms/step\n",
      "Epoch 44/10000\n",
      "Iteration 220 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0244 - val_mse: 0.0244 - 1s/epoch - 236ms/step\n",
      "Epoch 45/10000\n",
      "Iteration 225 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0238 - val_mse: 0.0238 - 1s/epoch - 249ms/step\n",
      "Epoch 46/10000\n",
      "Iteration 230 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0247 - val_mse: 0.0247 - 1s/epoch - 232ms/step\n",
      "Epoch 47/10000\n",
      "Iteration 235 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0228 - val_mse: 0.0228 - 1s/epoch - 246ms/step\n",
      "Epoch 48/10000\n",
      "Iteration 240 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0230 - val_mse: 0.0230 - 1s/epoch - 232ms/step\n",
      "Epoch 49/10000\n",
      "Iteration 245 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0224 - val_mse: 0.0224 - 1s/epoch - 240ms/step\n",
      "Epoch 50/10000\n",
      "Iteration 250 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0226 - val_mse: 0.0226 - 1s/epoch - 249ms/step\n",
      "Epoch 51/10000\n",
      "Iteration 255 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0245 - val_mse: 0.0245 - 1s/epoch - 228ms/step\n",
      "Epoch 52/10000\n",
      "Iteration 260 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0227 - val_mse: 0.0227 - 1s/epoch - 241ms/step\n",
      "Epoch 53/10000\n",
      "Iteration 265 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0227 - val_mse: 0.0227 - 1s/epoch - 238ms/step\n",
      "Epoch 54/10000\n",
      "Iteration 270 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0216 - val_mse: 0.0216 - 1s/epoch - 243ms/step\n",
      "Epoch 55/10000\n",
      "Iteration 275 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0211 - val_mse: 0.0211 - 1s/epoch - 238ms/step\n",
      "Epoch 56/10000\n",
      "Iteration 280 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0218 - val_mse: 0.0218 - 1s/epoch - 234ms/step\n",
      "Epoch 57/10000\n",
      "Iteration 285 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "5/5 - 1s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0214 - val_mse: 0.0214 - 1s/epoch - 236ms/step\n",
      "Epoch 58/10000\n",
      "Iteration 290 - Learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15604/2531969451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformedTargetRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_scaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# We update the keras model to the saved weights (note the use of _ for regressor and model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\sklearn\\compose\\_target.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"feature_names_in_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m         )\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         )\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1460\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1461\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m   2574\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2575\u001b[0m             \u001b[0mweight_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2576\u001b[1;33m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2577\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2578\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlazy_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msummary_metadata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         )\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     op = smart_cond.smart_cond(\n\u001b[1;32m--> 770\u001b[1;33m         should_record_summaries(), record, _nothing, name=\"summary_cond\")\n\u001b[0m\u001b[0;32m    771\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[1;34m()\u001b[0m\n\u001b[0;32m    755\u001b[0m       \u001b[1;31m# Note the identity to move the tensor to the CPU.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m         summary_tensor = tensor() if callable(tensor) else array_ops.identity(\n\u001b[0m\u001b[0;32m    758\u001b[0m             tensor)\n\u001b[0;32m    759\u001b[0m         write_summary_op = gen_summary_ops.write_summary(\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\util\\lazy_tensor_creator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CALL_IN_PROGRESS_SENTINEL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36mlazy_tensor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mlazy_tensor_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLazyTensorCreator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mlazy_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_buckets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         return tf.summary.write(\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36m_buckets\u001b[1;34m(data, bucket_count)\u001b[0m\n\u001b[0;32m    289\u001b[0m             )\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhen_empty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhen_nonempty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \"\"\"\n\u001b[1;32m-> 1391\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 instructions)\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eager_cond_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m   \u001b[1;31m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_eager_cond_implementation\u001b[1;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36mwhen_nonempty\u001b[1;34m()\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             return tf.cond(\n\u001b[1;32m--> 288\u001b[1;33m                 \u001b[0mhas_single_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhen_single_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhen_multiple_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m             )\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \"\"\"\n\u001b[1;32m-> 1391\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 instructions)\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eager_cond_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m   \u001b[1;31m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_eager_cond_implementation\u001b[1;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36mwhen_multiple_values\u001b[1;34m()\u001b[0m\n\u001b[0;32m    258\u001b[0m                 )\n\u001b[0;32m    259\u001b[0m                 bucket_counts = tf.cast(\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mone_hots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 )\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2311\u001b[0m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[1;32m-> 2312\u001b[1;33m                               _ReductionDims(input_tensor, axis))\n\u001b[0m\u001b[0;32m   2313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   2321\u001b[0m   return _may_reduce_to_scalar(\n\u001b[0;32m   2322\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2323\u001b[1;33m       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))\n\u001b[0m\u001b[0;32m   2324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  11226\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11227\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m> 11228\u001b[1;33m         _ctx, \"Sum\", name, input, axis, \"keep_dims\", keep_dims)\n\u001b[0m\u001b[0;32m  11229\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11230\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import datetime\n",
    "from pinard.nirs_pipelines import FeatureAugmentation\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "# Y scaler to scale test data set to create Y validation data\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(y_train.reshape((-1,1)))\n",
    "y_valid = y_scaler.transform(y_test.reshape((-1,1)))\n",
    "    \n",
    "\n",
    "# X transformation pipeline to create X validation data\n",
    "transformer_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('preprocessing', FeatureAugmentation(preprocessing)), \n",
    "])\n",
    "\n",
    "## we could have used a full standard pipeline and access transformers with:\n",
    "## estimator.regressor_[:-1].transform(X_test)\n",
    "transformer_pipeline.fit(X_train)\n",
    "X_valid = transformer_pipeline.transform(X_test)\n",
    "\n",
    "# KerasRegressor definition, with validation data and callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=1000, verbose=0, mode='min') \n",
    "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=100, verbose=1, epsilon=0.5e-5, mode='min')\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "k_regressor = KerasRegressor(model = keras_model,\n",
    "                            callbacks=[Auto_Save(), Print_LR(), early_stop, tensorboard_callback],\n",
    "                            epochs=10000,\n",
    "                            # random_state = rd_seed,\n",
    "                            fit__batch_size=BATCH_SIZE,\n",
    "                            fit__validation_data = (X_valid, y_valid),\n",
    "                            verbose = 2)\n",
    "\n",
    "# estimation pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('trans', transformer_pipeline), \n",
    "    ('KerasNN', k_regressor)\n",
    "])\n",
    "\n",
    "estimator = TransformedTargetRegressor(regressor = pipeline, transformer = y_scaler)\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# We update the keras model to the saved weights (note the use of _ for regressor and model)\n",
    "estimator.regressor_[1].model_.set_weights(Auto_Save.best_weights)\n",
    "\n",
    "Y_preds = estimator.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(y_test, Y_preds))\n",
    "print(\"MSE\", mean_squared_error(y_test, Y_preds))\n",
    "print(\"RMSE\", math.sqrt(mean_squared_error(y_test, Y_preds)))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, Y_preds))\n",
    "print(\"R²\", r2_score(y_test, Y_preds))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "plt.plot(Y_preds, y_test, 'ro', alpha=0.4, markersize=3)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('observed')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCeption 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = models.xception((256,3))\n",
    "xception.compile(optimizer='adam', \n",
    "                 loss='mean_squared_error', \n",
    "                 metrics=['mae','mse'])\n",
    "\n",
    "# plot_model(xception, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "history = xception.fit(X_trainEff, \n",
    "                       y_trainEff, \n",
    "                       epochs=200, \n",
    "                       batch_size=64,\n",
    "                       callbacks=[Auto_Save()],\n",
    "                       validation_data=(X_valid, y_valid))\n",
    "# Predict test fold\n",
    "xception.set_weights(Auto_Save.best_weights)\n",
    "Y_preds = xception.predict(X_valid)\n",
    "Y_preds = y_scaler.inverse_transform(Y_preds)\n",
    "print(\"MAE\", mean_absolute_error(y_test, Y_preds))\n",
    "print(\"MSE\", mean_squared_error(y_test, Y_preds))\n",
    "print(\"RMSE\", math.sqrt(mean_squared_error(y_test, Y_preds)))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, Y_preds))\n",
    "print(\"R²\", r2_score(y_test, Y_preds))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "plt.plot(Y_preds, y_test, 'ro', alpha=0.4, markersize=5)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('observed')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation with Keras Regressor\n",
    "\n",
    "sklearn cv_validation does not consider the best version of the keras regressor.\n",
    "The following example handles the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "kfold = RepeatedKFold(n_splits= 4, n_repeats= 2, random_state=rd_seed)\n",
    "\n",
    "fold = 0\n",
    "for train, test in kfold.split(y):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    # prepare validation data\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(y_train.reshape((-1,1)))\n",
    "    y_valid = y_scaler.transform(y_test.reshape((-1,1)))\n",
    "    transformer_pipeline.fit(X_train)\n",
    "    X_valid = transformer_pipeline.transform(X_test)\n",
    "    \n",
    "    # declare and fit regressor    \n",
    "    k_regressor = KerasRegressor(model = keras_model,\n",
    "                            callbacks=[Auto_Save(), Print_LR(), early_stop],\n",
    "                            epochs=EPOCHS, \n",
    "                            fit__batch_size=BATCH_SIZE,\n",
    "                            fit__validation_data = (X_valid, y_valid),\n",
    "                            verbose = 0)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('trans', transformer_pipeline), \n",
    "        ('KerasNN', k_regressor)\n",
    "    ])\n",
    "\n",
    "    estimator = TransformedTargetRegressor(regressor = pipeline, transformer = y_scaler)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict test fold\n",
    "    estimator.regressor_[1].model_.set_weights(Auto_Save.best_weights)\n",
    "    Y_preds = estimator.predict(X_test)\n",
    "    \n",
    "    print(\"Fold:\", fold, \"- MSE:\", mean_squared_error(y_test, Y_preds), \"- R²:\", r2_score(y_test, Y_preds))\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "def clear_gpu():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "    \n",
    "clear_gpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pynirsENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b09f6e5407ec4329146609a0cb08cbbe4720f97bb26598a93c421b663bd10d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
