{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### init random seeds\n",
    "rd_seed = 13246\n",
    "np.random.seed(rd_seed)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pinard import preprocessor as pp\n",
    "\n",
    "### Declare preprocessing pipeline components\n",
    "preprocessing = [   ('id', pp.IdentityTransformer()),\n",
    "                    ('savgol', pp.SavitzkyGolay()),\n",
    "                    ('derivate', pp.Derivate()), \n",
    "                    ('gaussian1', pp.Gaussian(order = 1, sigma = 2)),\n",
    "                    ('gaussian2', pp.Gaussian(order = 2, sigma = 1)),\n",
    "                    ('haar', pp.Wavelet('haar')),\n",
    "                    ('savgol*savgol', Pipeline([('_sg1',pp.SavitzkyGolay()),('_sg2',pp.SavitzkyGolay())])),\n",
    "                    ('gaussian1*savgol', Pipeline([('_g1',pp.Gaussian(order = 1, sigma = 2)),('_sg3',pp.SavitzkyGolay())])),\n",
    "                    ('gaussian2*savgol', Pipeline([('_g2',pp.Gaussian(order = 1, sigma = 2)),('_sg4',pp.SavitzkyGolay())])),\n",
    "                    ('haar*savgol', Pipeline([('_haar2',pp.Wavelet('haar')),('_sg5',pp.SavitzkyGolay())]))\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0522316  1.0564474  1.0320108  ... 0.5621798  0.56231886 0.5622432 ]\n",
      " [0.91029036 0.9535987  0.9861997  ... 0.5564785  0.5562965  0.55541193]\n",
      " [0.7547634  0.77333385 0.783736   ... 0.46846136 0.46816158 0.4678402 ]\n",
      " ...\n",
      " [0.6774115  0.6749243  0.6887683  ... 0.45818323 0.45851737 0.4584935 ]\n",
      " [0.7275998  0.7463403  0.7508709  ... 0.44724375 0.44707114 0.44744077]\n",
      " [0.7024517  0.70507336 0.71183866 ... 0.45939925 0.45958665 0.4589455 ]] [50.04759598 43.89248657 51.19988632 46.24049759 53.12453461 43.63124466\n",
      " 33.20572281 48.34818268 51.57919693 42.81207275]\n"
     ]
    }
   ],
   "source": [
    "from pinard import nirs_set as n_set\n",
    "\n",
    "### Load data\n",
    "n = n_set.NIRS_Set('data')\n",
    "X, y = n.load('Xcal.csv', 'Ycal.csv', x_hdr=0, y_hdr=0, y_cols=0)\n",
    "print(X[0:10], y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1.0816270596217166\n",
      "MSE 2.4316124872821887\n",
      "MAPE 0.024215514567072056\n",
      "R² 0.7906370594445927\n"
     ]
    }
   ],
   "source": [
    "## Simple xgboost pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "xgb =  XGBRegressor()\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('preprocessing', FeatureUnion(preprocessing)), \n",
    "    ('XGB', xgb)\n",
    "])\n",
    "\n",
    "estimator = TransformedTargetRegressor(regressor = pipeline, transformer = MinMaxScaler())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = rd_seed)\n",
    "estimator.fit(X_train, y_train)\n",
    "Y_preds = estimator.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(y_test, Y_preds))\n",
    "print(\"MSE\", mean_squared_error(y_test, Y_preds))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, Y_preds))\n",
    "print(\"R²\", r2_score(y_test, Y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.9239768627451542\n",
      "MSE 1.6106460074820232\n",
      "MAPE 0.020502684600532527\n",
      "R² 0.8613226465631612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "## Simple PLS pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('preprocessing', FeatureUnion(preprocessing)), \n",
    "    ('pls', PLSRegression(n_components=10))\n",
    "])\n",
    "\n",
    "estimator = TransformedTargetRegressor(regressor = pipeline, transformer = MinMaxScaler())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = rd_seed)\n",
    "estimator.fit(X_train, y_train)\n",
    "Y_preds = estimator.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(y_test, Y_preds))\n",
    "print(\"MSE\", mean_squared_error(y_test, Y_preds))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, Y_preds))\n",
    "print(\"R²\", r2_score(y_test, Y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\PyNIRS_env\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    }
   ],
   "source": [
    "## KERAS Model\n",
    "##TODO > remove keraswrapper for sciKeras wrapper\n",
    "\n",
    "from pinard.nirs_pipelines import FeatureAugmentation\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, SpatialDropout1D,BatchNormalization,Flatten, Dropout\n",
    "\n",
    "tensorflow.random.set_seed(rd_seed)\n",
    "\n",
    "def keras_model(optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    model.add(SpatialDropout1D(0.08))\n",
    "    model.add(Conv1D (filters=8, kernel_size=15, strides=5, activation='selu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D (filters=64, kernel_size=21, strides=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D (filters=32, kernel_size=5, strides=3, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('preprocessing', FeatureAugmentation(preprocessing)), \n",
    "    ('KerasNN',  KerasRegressor(build_fn = keras_model, epochs=2000, batch_size=1000, verbose = 0))\n",
    "])\n",
    "\n",
    "estimator = TransformedTargetRegressor(regressor = pipeline, transformer = MinMaxScaler())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = rd_seed)\n",
    "estimator.fit(X_train, y_train)\n",
    "Y_preds = estimator.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(y_test, Y_preds))\n",
    "print(\"MSE\", mean_squared_error(y_test, Y_preds))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, Y_preds))\n",
    "print(\"R²\", r2_score(y_test, Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Explainer\n",
    "\n",
    "import shap\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns # for correlation heatmap\n",
    "\n",
    "# perm_importance = permutation_importance(xgb, X_test, y_test)\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "# plt.barh(np.arrange(0,len(X_test[0],1))[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")\n",
    "explainer = shap.TreeExplainer(estimator)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f8d3e8f8c7640fbbf35b62c8de936b6d82f4a593a89ad30b44a7b3fb146f57e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('PyNIRS_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
