{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:48:26,119 - INFO - ================================================================================\n",
      "2024-10-31 11:48:26,120 - INFO - ### PREPARING DATA ###\n",
      "2024-10-31 11:48:26,120 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Browsing sample_data/Malaria2024\n",
      "No train_group file found for sample_data/Malaria2024.\n",
      "No test_group file found for sample_data/Malaria2024.\n",
      "{'initial_shape': (2996, 1665), 'delimiter': ';', 'numeric_delimiter': '.', 'header_line': 0, 'final_shape': (2996, 1665), 'na_handling': {'strategy': 'abort', 'nb_removed_rows': None, 'removed_rows': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:48:28,315 - INFO - Dataset(x_train:(2996, 1665) - y_train:(2996, 1), x_test:(1285, 1665) - y_test:(1285, 1))\n",
      "2024-10-31 11:48:28,316 - INFO - ### PROCESSING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_shape': (1285, 1665), 'delimiter': ';', 'numeric_delimiter': '.', 'header_line': 0, 'final_shape': (1285, 1665), 'na_handling': {'strategy': 'abort', 'nb_removed_rows': None, 'removed_rows': None}}\n",
      "(1, 2996, 1, 1665) (2996, 1)\n",
      "{np.float32(0.0): 2870, np.float32(1.0): 126}\n",
      "{np.float32(0.0): 0, np.float32(1.0): 2744}\n",
      "(1, 5740, 1, 1665) (5740, 1)\n",
      "{np.float32(0.0): 2870, np.float32(1.0): 2870}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:48:34,030 - INFO - Dataset(x_train:(5740, 6660) - y_train:(5740, 1), x_test:(1285, 6660) - y_test:(1285, 1))\n",
      "Folds size: 3826-1914, 3827-1913, 3827-1913\n",
      "2024-10-31 11:48:34,031 - INFO - ### PREPARING MODEL ###\n",
      "2024-10-31 11:48:34,129 - INFO - Running config > {'dataset': 'sample_data/Malaria2024', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'samples': [{'class': 'pinard.transformations.Rotate_Translate', 'params': None}], 'balance': True}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'features': [None, [{'class': 'pinard.transformations.Gaussian', 'params': {'copy': True, 'order': 2, 'sigma': 1}}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': {'copy': True, 'with_mean': True, 'with_std': True}}], {'class': 'pinard.transformations.SavitzkyGolay', 'params': {'copy': True, 'delta': 1.0, 'deriv': 0, 'polyorder': 3, 'window_length': 11}}, {'class': 'pinard.transformations.Gaussian', 'params': {'copy': True, 'order': 2, 'sigma': 1}}]}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'pinard.presets.ref_models.bacon_classification'}, 'experiment': {'task': 'classification', 'training_params': {'epochs': 150, 'loss': 'binary_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2024-10-31 11:48:34,131 - INFO - Starting new experiment experiment_1cdc8d05.\n",
      "2024-10-31 11:48:34,133 - INFO - Experiment prepared at results\\sample_dataMalaria2024\\bacon_classification\\experiment_1cdc8d05\n",
      "2024-10-31 11:48:34,134 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: tensorflow\n",
      "Training fold with shapes: (3826, 1665, 4) (3826, 1) (1914, 1665, 4) (1914, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (3826, 1665, 4) (3826, 1) (1914, 1665, 4) (1914, 1)\n",
      "Epoch 1/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5207 - loss: 0.7038 - val_accuracy: 0.5005 - val_loss: 0.7439\n",
      "Epoch 2/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.5055 - val_accuracy: 0.5005 - val_loss: 0.5976\n",
      "Epoch 3/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.3937 - val_accuracy: 0.5543 - val_loss: 0.5711\n",
      "Epoch 4/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 0.3248 - val_accuracy: 0.9373 - val_loss: 0.1923\n",
      "Epoch 5/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8970 - loss: 0.2542 - val_accuracy: 0.5010 - val_loss: 1.5237\n",
      "Epoch 6/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2116 - val_accuracy: 0.9702 - val_loss: 0.1242\n",
      "Epoch 7/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1634 - val_accuracy: 0.7665 - val_loss: 0.6586\n",
      "Epoch 8/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.1728 - val_accuracy: 0.5219 - val_loss: 1.4519\n",
      "Epoch 9/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1351 - val_accuracy: 0.8281 - val_loss: 0.4133\n",
      "Epoch 10/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1112 - val_accuracy: 0.9833 - val_loss: 0.0638\n",
      "Epoch 11/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.1043 - val_accuracy: 0.8600 - val_loss: 0.2212\n",
      "Epoch 12/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.0971 - val_accuracy: 0.9859 - val_loss: 0.0574\n",
      "Epoch 13/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0742 - val_accuracy: 0.8218 - val_loss: 0.4161\n",
      "Epoch 14/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9677 - loss: 0.0963 - val_accuracy: 0.9864 - val_loss: 0.0469\n",
      "Epoch 15/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0734 - val_accuracy: 0.9039 - val_loss: 0.2498\n",
      "Epoch 16/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0577 - val_accuracy: 0.9744 - val_loss: 0.0788\n",
      "Epoch 17/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0681 - val_accuracy: 0.9890 - val_loss: 0.0349\n",
      "Epoch 18/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0574 - val_accuracy: 0.9969 - val_loss: 0.0176\n",
      "Epoch 19/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0643 - val_accuracy: 0.9838 - val_loss: 0.0428\n",
      "Epoch 20/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0439 - val_accuracy: 0.8777 - val_loss: 0.3460\n",
      "Epoch 21/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9883 - loss: 0.0390 - val_accuracy: 0.9869 - val_loss: 0.0381\n",
      "Epoch 22/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0471 - val_accuracy: 0.9953 - val_loss: 0.0232\n",
      "Epoch 23/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9827 - loss: 0.0466 - val_accuracy: 0.9650 - val_loss: 0.1058\n",
      "Epoch 24/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0394 - val_accuracy: 0.9963 - val_loss: 0.0155\n",
      "Epoch 25/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0474 - val_accuracy: 0.9875 - val_loss: 0.0399\n",
      "Epoch 26/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0372 - val_accuracy: 0.9979 - val_loss: 0.0141\n",
      "Epoch 27/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0323 - val_accuracy: 0.6385 - val_loss: 0.9724\n",
      "Epoch 28/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0290 - val_accuracy: 0.9958 - val_loss: 0.0155\n",
      "Epoch 29/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0314 - val_accuracy: 0.9859 - val_loss: 0.0848\n",
      "Epoch 30/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0430 - val_accuracy: 0.9190 - val_loss: 0.2319\n",
      "Epoch 31/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0491 - val_accuracy: 0.9880 - val_loss: 0.0349\n",
      "Epoch 32/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0496 - val_accuracy: 0.9545 - val_loss: 0.1402\n",
      "Epoch 33/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0296 - val_accuracy: 0.9948 - val_loss: 0.0177\n",
      "Epoch 34/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0340 - val_accuracy: 0.9734 - val_loss: 0.0862\n",
      "Epoch 35/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0228 - val_accuracy: 0.9932 - val_loss: 0.0216\n",
      "Epoch 36/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0287 - val_accuracy: 0.9692 - val_loss: 0.0907\n",
      "Epoch 37/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0293 - val_accuracy: 0.9911 - val_loss: 0.0277\n",
      "Epoch 38/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0342 - val_accuracy: 0.9828 - val_loss: 0.0567\n",
      "Epoch 39/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0280 - val_accuracy: 0.9953 - val_loss: 0.0241\n",
      "Epoch 40/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0351 - val_accuracy: 0.9963 - val_loss: 0.0139\n",
      "Epoch 41/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0229 - val_accuracy: 0.9974 - val_loss: 0.0107\n",
      "Epoch 42/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0225 - val_accuracy: 0.9901 - val_loss: 0.0354\n",
      "Epoch 43/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0232 - val_accuracy: 0.9927 - val_loss: 0.0245\n",
      "Epoch 44/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0339 - val_accuracy: 0.9801 - val_loss: 0.0669\n",
      "Epoch 45/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0381 - val_accuracy: 0.9639 - val_loss: 0.1020\n",
      "Epoch 46/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0144 - val_accuracy: 0.9963 - val_loss: 0.0134\n",
      "Epoch 47/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0203 - val_accuracy: 0.9948 - val_loss: 0.0186\n",
      "Epoch 48/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0355 - val_accuracy: 0.6964 - val_loss: 1.1531\n",
      "Epoch 49/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0263 - val_accuracy: 0.9916 - val_loss: 0.0324\n",
      "Epoch 50/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0115 - val_accuracy: 0.9801 - val_loss: 0.0579\n",
      "Epoch 51/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0341 - val_accuracy: 0.9969 - val_loss: 0.0115\n",
      "Epoch 52/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0223 - val_accuracy: 0.8903 - val_loss: 0.2728\n",
      "Epoch 53/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0468 - val_accuracy: 0.9410 - val_loss: 0.1705\n",
      "Epoch 54/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0131 - val_accuracy: 0.9963 - val_loss: 0.0159\n",
      "Epoch 55/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0193 - val_accuracy: 0.9943 - val_loss: 0.0217\n",
      "Epoch 56/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0210 - val_accuracy: 0.9963 - val_loss: 0.0125\n",
      "Epoch 57/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0154 - val_accuracy: 0.9807 - val_loss: 0.0680\n",
      "Epoch 58/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9577 - val_loss: 0.1525\n",
      "Epoch 59/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0183 - val_accuracy: 0.9833 - val_loss: 0.0564\n",
      "Epoch 60/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0225 - val_accuracy: 0.9922 - val_loss: 0.0262\n",
      "Epoch 61/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0146 - val_accuracy: 0.9890 - val_loss: 0.0262\n",
      "Epoch 62/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0198 - val_accuracy: 0.9514 - val_loss: 0.1645\n",
      "Epoch 63/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0191 - val_accuracy: 0.9807 - val_loss: 0.0655\n",
      "Epoch 64/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0166 - val_accuracy: 0.9901 - val_loss: 0.0445\n",
      "Epoch 65/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0178 - val_accuracy: 0.9937 - val_loss: 0.0220\n",
      "Epoch 66/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0410\n",
      "Epoch 67/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0188 - val_accuracy: 0.7618 - val_loss: 0.8243\n",
      "Epoch 68/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0236 - val_accuracy: 0.9676 - val_loss: 0.0760\n",
      "Epoch 69/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0268 - val_accuracy: 0.5308 - val_loss: 3.2400\n",
      "Epoch 70/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9842 - loss: 0.0448 - val_accuracy: 0.9807 - val_loss: 0.0600\n",
      "Epoch 71/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0278 - val_accuracy: 0.9843 - val_loss: 0.0523\n",
      "Epoch 72/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0143 - val_accuracy: 0.9754 - val_loss: 0.0780\n",
      "Epoch 73/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0110 - val_accuracy: 0.9969 - val_loss: 0.0125\n",
      "Epoch 74/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0241 - val_accuracy: 0.9901 - val_loss: 0.0411\n",
      "Epoch 75/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0145 - val_accuracy: 0.9441 - val_loss: 0.1855\n",
      "Epoch 76/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0228 - val_accuracy: 0.9514 - val_loss: 0.1502\n",
      "Epoch 77/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0220 - val_accuracy: 0.9754 - val_loss: 0.0729\n",
      "Epoch 78/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0131 - val_accuracy: 0.9577 - val_loss: 0.1278\n",
      "Epoch 79/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0202 - val_accuracy: 0.6855 - val_loss: 1.1097\n",
      "Epoch 80/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.9535 - val_loss: 0.1400\n",
      "Epoch 81/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0168 - val_accuracy: 0.8265 - val_loss: 0.5639\n",
      "Epoch 82/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0217 - val_accuracy: 0.9916 - val_loss: 0.0298\n",
      "Epoch 83/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9828 - val_loss: 0.0491\n",
      "Epoch 84/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0187 - val_accuracy: 0.9540 - val_loss: 0.1351\n",
      "Epoch 85/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.9645 - val_loss: 0.1167\n",
      "Epoch 86/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 0.9969 - val_loss: 0.0108\n",
      "Epoch 87/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.9911 - val_loss: 0.0316\n",
      "Epoch 88/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0119 - val_accuracy: 0.9906 - val_loss: 0.0370\n",
      "Epoch 89/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0162 - val_accuracy: 0.9765 - val_loss: 0.0694\n",
      "Epoch 90/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0164 - val_accuracy: 0.9833 - val_loss: 0.0636\n",
      "Epoch 91/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0204 - val_accuracy: 0.9122 - val_loss: 0.2754\n",
      "Training fold with shapes: (3827, 1665, 4) (3827, 1) (1913, 1665, 4) (1913, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (3827, 1665, 4) (3827, 1) (1913, 1665, 4) (1913, 1)\n",
      "Epoch 1/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5490 - loss: 0.6817 - val_accuracy: 0.6539 - val_loss: 0.5880\n",
      "Epoch 2/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7382 - loss: 0.5270 - val_accuracy: 0.4888 - val_loss: 1.2168\n",
      "Epoch 3/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.4107 - val_accuracy: 0.4888 - val_loss: 0.9770\n",
      "Epoch 4/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8361 - loss: 0.3840 - val_accuracy: 0.4888 - val_loss: 1.4699\n",
      "Epoch 5/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.2662 - val_accuracy: 0.5091 - val_loss: 1.1332\n",
      "Epoch 6/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8932 - loss: 0.2612 - val_accuracy: 0.7130 - val_loss: 0.5084\n",
      "Epoch 7/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2201 - val_accuracy: 0.8338 - val_loss: 0.3114\n",
      "Epoch 8/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9370 - loss: 0.1755 - val_accuracy: 0.9242 - val_loss: 0.1614\n",
      "Epoch 9/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9366 - loss: 0.1852 - val_accuracy: 0.7339 - val_loss: 0.5919\n",
      "Epoch 10/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.1471 - val_accuracy: 0.8599 - val_loss: 0.3256\n",
      "Epoch 11/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1215 - val_accuracy: 0.8369 - val_loss: 0.4079\n",
      "Epoch 12/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1111 - val_accuracy: 0.7601 - val_loss: 0.6616\n",
      "Epoch 13/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9624 - loss: 0.1071 - val_accuracy: 0.9880 - val_loss: 0.0507\n",
      "Epoch 14/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0860 - val_accuracy: 0.9686 - val_loss: 0.0880\n",
      "Epoch 15/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9708 - loss: 0.0850 - val_accuracy: 0.8761 - val_loss: 0.2474\n",
      "Epoch 16/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0918 - val_accuracy: 0.9901 - val_loss: 0.0351\n",
      "Epoch 17/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0610 - val_accuracy: 0.9749 - val_loss: 0.0812\n",
      "Epoch 18/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0714 - val_accuracy: 0.9556 - val_loss: 0.1008\n",
      "Epoch 19/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0721 - val_accuracy: 0.9665 - val_loss: 0.0917\n",
      "Epoch 20/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0483 - val_accuracy: 0.9995 - val_loss: 0.0128\n",
      "Epoch 21/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0547 - val_accuracy: 0.9697 - val_loss: 0.0836\n",
      "Epoch 22/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0583 - val_accuracy: 0.9990 - val_loss: 0.0108\n",
      "Epoch 23/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9827 - loss: 0.0462 - val_accuracy: 0.5551 - val_loss: 1.4211\n",
      "Epoch 24/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0363 - val_accuracy: 0.6984 - val_loss: 0.9517\n",
      "Epoch 25/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0348 - val_accuracy: 0.8113 - val_loss: 0.3799\n",
      "Epoch 26/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9851 - loss: 0.0435 - val_accuracy: 0.9038 - val_loss: 0.2947\n",
      "Epoch 27/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0460 - val_accuracy: 0.9969 - val_loss: 0.0150\n",
      "Epoch 28/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0290 - val_accuracy: 0.8604 - val_loss: 0.4124\n",
      "Epoch 29/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0347 - val_accuracy: 0.9922 - val_loss: 0.0345\n",
      "Epoch 30/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0469 - val_accuracy: 0.9624 - val_loss: 0.1139\n",
      "Epoch 31/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0520 - val_accuracy: 0.9514 - val_loss: 0.1453\n",
      "Epoch 32/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0402 - val_accuracy: 0.8327 - val_loss: 0.4913\n",
      "Epoch 33/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0262 - val_accuracy: 0.9990 - val_loss: 0.0088\n",
      "Epoch 34/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0284 - val_accuracy: 0.9216 - val_loss: 0.2512\n",
      "Epoch 35/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0319 - val_accuracy: 0.9817 - val_loss: 0.0540\n",
      "Epoch 36/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0263 - val_accuracy: 0.8259 - val_loss: 0.3709\n",
      "Epoch 37/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0457 - val_accuracy: 0.7554 - val_loss: 0.6846\n",
      "Epoch 38/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0229 - val_accuracy: 0.9258 - val_loss: 0.2335\n",
      "Epoch 39/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0209 - val_accuracy: 0.9958 - val_loss: 0.0108\n",
      "Epoch 40/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0226 - val_accuracy: 0.9916 - val_loss: 0.0290\n",
      "Epoch 41/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0233 - val_accuracy: 0.9916 - val_loss: 0.0260\n",
      "Epoch 42/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0420 - val_accuracy: 0.6508 - val_loss: 1.2655\n",
      "Epoch 43/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0327 - val_accuracy: 0.9969 - val_loss: 0.0122\n",
      "Epoch 44/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0214 - val_accuracy: 0.9681 - val_loss: 0.0957\n",
      "Epoch 45/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0276 - val_accuracy: 0.9969 - val_loss: 0.0143\n",
      "Epoch 46/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0282 - val_accuracy: 0.9942 - val_loss: 0.0284\n",
      "Epoch 47/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0260 - val_accuracy: 0.8312 - val_loss: 0.5217\n",
      "Epoch 48/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0233 - val_accuracy: 0.8108 - val_loss: 0.5228\n",
      "Epoch 49/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0237 - val_accuracy: 0.9942 - val_loss: 0.0218\n",
      "Epoch 50/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0119 - val_accuracy: 0.9984 - val_loss: 0.0086\n",
      "Epoch 51/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0317 - val_accuracy: 0.9901 - val_loss: 0.0304\n",
      "Epoch 52/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0244 - val_accuracy: 0.9963 - val_loss: 0.0159\n",
      "Epoch 53/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0158 - val_accuracy: 0.9827 - val_loss: 0.0383\n",
      "Epoch 54/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0271 - val_accuracy: 0.9906 - val_loss: 0.0325\n",
      "Epoch 55/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0332 - val_accuracy: 0.9848 - val_loss: 0.0412\n",
      "Epoch 56/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0284 - val_accuracy: 0.9958 - val_loss: 0.0180\n",
      "Epoch 57/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0253 - val_accuracy: 0.9963 - val_loss: 0.0121\n",
      "Epoch 58/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0200 - val_accuracy: 0.9770 - val_loss: 0.0702\n",
      "Epoch 59/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0230 - val_accuracy: 0.9791 - val_loss: 0.0614\n",
      "Epoch 60/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0238 - val_accuracy: 0.9937 - val_loss: 0.0170\n",
      "Epoch 61/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0235 - val_accuracy: 0.9252 - val_loss: 0.2342\n",
      "Epoch 62/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0113 - val_accuracy: 0.9932 - val_loss: 0.0226\n",
      "Epoch 63/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9744 - val_loss: 0.0806\n",
      "Epoch 64/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0399 - val_accuracy: 0.9958 - val_loss: 0.0158\n",
      "Epoch 65/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0236 - val_accuracy: 0.9775 - val_loss: 0.0442\n",
      "Epoch 66/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0261 - val_accuracy: 0.9953 - val_loss: 0.0161\n",
      "Epoch 67/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0112 - val_accuracy: 0.9843 - val_loss: 0.0473\n",
      "Epoch 68/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0183 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
      "Epoch 69/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0179 - val_accuracy: 0.9969 - val_loss: 0.0113\n",
      "Epoch 70/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0139 - val_accuracy: 0.6472 - val_loss: 1.2265\n",
      "Epoch 71/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9869 - val_loss: 0.0427\n",
      "Epoch 72/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0127 - val_accuracy: 0.9875 - val_loss: 0.0386\n",
      "Epoch 73/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0200 - val_accuracy: 0.9561 - val_loss: 0.1427\n",
      "Epoch 74/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.9974 - val_loss: 0.0107\n",
      "Epoch 75/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0194 - val_accuracy: 0.9441 - val_loss: 0.1824\n",
      "Epoch 76/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0317 - val_accuracy: 0.9331 - val_loss: 0.2103\n",
      "Epoch 77/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0202 - val_accuracy: 0.9901 - val_loss: 0.0362\n",
      "Epoch 78/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0223 - val_accuracy: 0.9712 - val_loss: 0.0917\n",
      "Epoch 79/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0169 - val_accuracy: 0.8447 - val_loss: 0.3515\n",
      "Epoch 80/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0249 - val_accuracy: 0.9963 - val_loss: 0.0112\n",
      "Epoch 81/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0138 - val_accuracy: 0.9953 - val_loss: 0.0283\n",
      "Epoch 82/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0111 - val_accuracy: 0.9890 - val_loss: 0.0363\n",
      "Epoch 83/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0128 - val_accuracy: 0.9953 - val_loss: 0.0106\n",
      "Epoch 84/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.9854 - val_loss: 0.0393\n",
      "Epoch 85/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0105 - val_accuracy: 0.9984 - val_loss: 0.0061\n",
      "Epoch 86/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0173 - val_accuracy: 0.9875 - val_loss: 0.1041\n",
      "Epoch 87/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0095 - val_accuracy: 0.9948 - val_loss: 0.0147\n",
      "Epoch 88/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0204 - val_accuracy: 0.9090 - val_loss: 0.2948\n",
      "Epoch 89/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0177 - val_accuracy: 0.9624 - val_loss: 0.1261\n",
      "Epoch 90/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0178 - val_accuracy: 0.8709 - val_loss: 0.3733\n",
      "Epoch 91/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0109 - val_accuracy: 0.9263 - val_loss: 0.2495\n",
      "Epoch 92/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0156 - val_accuracy: 0.9143 - val_loss: 0.2926\n",
      "Epoch 93/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0166 - val_accuracy: 0.5076 - val_loss: 2.2159\n",
      "Epoch 94/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0183 - val_accuracy: 0.9948 - val_loss: 0.0141\n",
      "Epoch 95/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.9827 - val_loss: 0.0480\n",
      "Epoch 96/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0136 - val_accuracy: 0.9969 - val_loss: 0.0083\n",
      "Epoch 97/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9859 - val_loss: 0.0487\n",
      "Epoch 98/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0328 - val_accuracy: 0.9827 - val_loss: 0.1123\n",
      "Epoch 99/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0114 - val_accuracy: 0.9895 - val_loss: 0.0376\n",
      "Epoch 100/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0152 - val_accuracy: 0.9843 - val_loss: 0.0574\n",
      "Epoch 101/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 0.9932 - val_loss: 0.0190\n",
      "Epoch 102/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.9958 - val_loss: 0.0100\n",
      "Epoch 103/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9812 - val_loss: 0.0587\n",
      "Epoch 104/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0167 - val_accuracy: 0.9367 - val_loss: 0.1829\n",
      "Epoch 105/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0254 - val_accuracy: 0.9932 - val_loss: 0.0159\n",
      "Epoch 106/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0170 - val_accuracy: 0.9765 - val_loss: 0.0708\n",
      "Epoch 107/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0137 - val_accuracy: 0.9854 - val_loss: 0.0576\n",
      "Epoch 108/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0401 - val_accuracy: 0.9760 - val_loss: 0.0643\n",
      "Epoch 109/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9974 - val_loss: 0.0068\n",
      "Epoch 110/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.9624 - val_loss: 0.1409\n",
      "Epoch 111/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.7940 - val_loss: 0.6365\n",
      "Epoch 112/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9984 - val_loss: 0.0049\n",
      "Epoch 113/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0129 - val_accuracy: 0.9770 - val_loss: 0.0538\n",
      "Epoch 114/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.9895 - val_loss: 0.0295\n",
      "Epoch 115/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0116 - val_accuracy: 0.9848 - val_loss: 0.0443\n",
      "Epoch 116/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9953 - val_loss: 0.0203\n",
      "Epoch 117/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0231 - val_accuracy: 0.9984 - val_loss: 0.0049\n",
      "Epoch 118/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0208 - val_accuracy: 0.9958 - val_loss: 0.0135\n",
      "Training fold with shapes: (3827, 1665, 4) (3827, 1) (1913, 1665, 4) (1913, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (3827, 1665, 4) (3827, 1) (1913, 1665, 4) (1913, 1)\n",
      "Epoch 1/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 0.6826 - val_accuracy: 0.5562 - val_loss: 0.5956\n",
      "Epoch 2/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7654 - loss: 0.5026 - val_accuracy: 0.6827 - val_loss: 0.5685\n",
      "Epoch 3/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7922 - loss: 0.4438 - val_accuracy: 0.7198 - val_loss: 0.5232\n",
      "Epoch 4/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8429 - loss: 0.3635 - val_accuracy: 0.7637 - val_loss: 0.4559\n",
      "Epoch 5/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.3163 - val_accuracy: 0.8364 - val_loss: 0.3499\n",
      "Epoch 6/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.2647 - val_accuracy: 0.5107 - val_loss: 1.8391\n",
      "Epoch 7/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.2465 - val_accuracy: 0.7062 - val_loss: 0.5681\n",
      "Epoch 8/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9218 - loss: 0.2161 - val_accuracy: 0.6461 - val_loss: 1.0209\n",
      "Epoch 9/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.2060 - val_accuracy: 0.5165 - val_loss: 1.6426\n",
      "Epoch 10/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.2035 - val_accuracy: 0.6351 - val_loss: 0.9345\n",
      "Epoch 11/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.1419 - val_accuracy: 0.7642 - val_loss: 0.5608\n",
      "Epoch 12/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.1076 - val_accuracy: 0.9885 - val_loss: 0.0603\n",
      "Epoch 13/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1185 - val_accuracy: 0.7355 - val_loss: 0.5994\n",
      "Epoch 14/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.1196 - val_accuracy: 0.9205 - val_loss: 0.1652\n",
      "Epoch 15/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.1020 - val_accuracy: 0.7538 - val_loss: 0.5954\n",
      "Epoch 16/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9703 - loss: 0.0982 - val_accuracy: 0.6482 - val_loss: 0.9279\n",
      "Epoch 17/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0723 - val_accuracy: 0.9901 - val_loss: 0.0392\n",
      "Epoch 18/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0729 - val_accuracy: 0.9420 - val_loss: 0.1622\n",
      "Epoch 19/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.0744 - val_accuracy: 0.9942 - val_loss: 0.0468\n",
      "Epoch 20/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0696 - val_accuracy: 0.9702 - val_loss: 0.0937\n",
      "Epoch 21/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0551 - val_accuracy: 0.9890 - val_loss: 0.0685\n",
      "Epoch 22/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0701 - val_accuracy: 0.9942 - val_loss: 0.0249\n",
      "Epoch 23/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0422 - val_accuracy: 0.9315 - val_loss: 0.1856\n",
      "Epoch 24/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0451 - val_accuracy: 0.9739 - val_loss: 0.0740\n",
      "Epoch 25/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0536 - val_accuracy: 0.9760 - val_loss: 0.0684\n",
      "Epoch 26/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0497 - val_accuracy: 0.9922 - val_loss: 0.0320\n",
      "Epoch 27/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9716 - loss: 0.0802 - val_accuracy: 0.9869 - val_loss: 0.0393\n",
      "Epoch 28/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0366 - val_accuracy: 0.9895 - val_loss: 0.0320\n",
      "Epoch 29/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0309 - val_accuracy: 0.9812 - val_loss: 0.0571\n",
      "Epoch 30/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0408 - val_accuracy: 0.9953 - val_loss: 0.0236\n",
      "Epoch 31/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0564 - val_accuracy: 0.8562 - val_loss: 0.4155\n",
      "Epoch 32/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0293 - val_accuracy: 0.9880 - val_loss: 0.0330\n",
      "Epoch 33/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0413 - val_accuracy: 0.9948 - val_loss: 0.0157\n",
      "Epoch 34/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0336 - val_accuracy: 0.9969 - val_loss: 0.0132\n",
      "Epoch 35/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0293 - val_accuracy: 0.9462 - val_loss: 0.1514\n",
      "Epoch 36/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0234 - val_accuracy: 0.9922 - val_loss: 0.0200\n",
      "Epoch 37/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0418 - val_accuracy: 0.9796 - val_loss: 0.0693\n",
      "Epoch 38/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0448 - val_accuracy: 0.9639 - val_loss: 0.0948\n",
      "Epoch 39/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0289 - val_accuracy: 0.9963 - val_loss: 0.0191\n",
      "Epoch 40/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0197 - val_accuracy: 0.9974 - val_loss: 0.0139\n",
      "Epoch 41/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0300 - val_accuracy: 0.9990 - val_loss: 0.0109\n",
      "Epoch 42/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0313 - val_accuracy: 0.9927 - val_loss: 0.0186\n",
      "Epoch 43/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0276 - val_accuracy: 0.9906 - val_loss: 0.0335\n",
      "Epoch 44/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0203 - val_accuracy: 0.6989 - val_loss: 0.9173\n",
      "Epoch 45/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.0398 - val_accuracy: 0.9535 - val_loss: 0.1100\n",
      "Epoch 46/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0347 - val_accuracy: 0.9937 - val_loss: 0.0354\n",
      "Epoch 47/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0303 - val_accuracy: 0.9749 - val_loss: 0.0970\n",
      "Epoch 48/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0374 - val_accuracy: 0.9969 - val_loss: 0.0115\n",
      "Epoch 49/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0257 - val_accuracy: 0.9932 - val_loss: 0.0293\n",
      "Epoch 50/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0188 - val_accuracy: 0.9472 - val_loss: 0.1656\n",
      "Epoch 51/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0300 - val_accuracy: 0.9969 - val_loss: 0.0085\n",
      "Epoch 52/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0181 - val_accuracy: 0.9990 - val_loss: 0.0065\n",
      "Epoch 53/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0242 - val_accuracy: 0.9948 - val_loss: 0.0153\n",
      "Epoch 54/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0266 - val_accuracy: 0.9979 - val_loss: 0.0073\n",
      "Epoch 55/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0196 - val_accuracy: 0.8735 - val_loss: 0.4147\n",
      "Epoch 56/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0206 - val_accuracy: 0.9796 - val_loss: 0.0691\n",
      "Epoch 57/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0275 - val_accuracy: 0.8578 - val_loss: 0.5016\n",
      "Epoch 58/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0210 - val_accuracy: 0.9995 - val_loss: 0.0072\n",
      "Epoch 59/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0090 - val_accuracy: 0.9916 - val_loss: 0.0273\n",
      "Epoch 60/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0183 - val_accuracy: 0.9733 - val_loss: 0.0801\n",
      "Epoch 61/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0225 - val_accuracy: 0.9922 - val_loss: 0.0294\n",
      "Epoch 62/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0241 - val_accuracy: 0.9854 - val_loss: 0.0442\n",
      "Epoch 63/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0174 - val_accuracy: 0.9937 - val_loss: 0.0186\n",
      "Epoch 64/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0182 - val_accuracy: 0.9760 - val_loss: 0.0868\n",
      "Epoch 65/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.9969 - val_loss: 0.0095\n",
      "Epoch 66/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0352 - val_accuracy: 0.9927 - val_loss: 0.0202\n",
      "Epoch 67/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0211 - val_accuracy: 0.9990 - val_loss: 0.0136\n",
      "Epoch 68/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0172 - val_accuracy: 0.9697 - val_loss: 0.0915\n",
      "Epoch 69/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0229 - val_accuracy: 0.9990 - val_loss: 0.0127\n",
      "Epoch 70/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0137 - val_accuracy: 0.9367 - val_loss: 0.2100\n",
      "Epoch 71/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0292 - val_accuracy: 0.9885 - val_loss: 0.0415\n",
      "Epoch 72/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0435 - val_accuracy: 0.8061 - val_loss: 0.6038\n",
      "Epoch 73/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0136 - val_accuracy: 0.9838 - val_loss: 0.0598\n",
      "Epoch 74/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.9817 - val_loss: 0.0509\n",
      "Epoch 75/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0254 - val_accuracy: 0.9984 - val_loss: 0.0074\n",
      "Epoch 76/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.9754 - val_loss: 0.0830\n",
      "Epoch 77/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0083 - val_accuracy: 0.9158 - val_loss: 0.2648\n",
      "Epoch 78/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0201 - val_accuracy: 0.9963 - val_loss: 0.0148\n",
      "Epoch 79/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0301 - val_accuracy: 0.9932 - val_loss: 0.0214\n",
      "Epoch 80/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0205 - val_accuracy: 0.9979 - val_loss: 0.0057\n",
      "Epoch 81/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0133 - val_accuracy: 0.8562 - val_loss: 0.3930\n",
      "Epoch 82/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0265 - val_accuracy: 0.9937 - val_loss: 0.0177\n",
      "Epoch 83/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 0.9864 - val_loss: 0.0552\n",
      "Epoch 84/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0104 - val_accuracy: 0.9922 - val_loss: 0.0280\n",
      "Epoch 85/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0132 - val_accuracy: 0.9409 - val_loss: 0.2271\n",
      "Epoch 86/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0233 - val_accuracy: 0.7365 - val_loss: 0.8094\n",
      "Epoch 87/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0147 - val_accuracy: 0.9854 - val_loss: 0.0415\n",
      "Epoch 88/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0175 - val_accuracy: 0.9953 - val_loss: 0.0158\n",
      "Epoch 89/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0185 - val_accuracy: 0.9948 - val_loss: 0.0170\n",
      "Epoch 90/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0167 - val_accuracy: 0.9953 - val_loss: 0.0283\n",
      "Epoch 91/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0193 - val_accuracy: 0.9859 - val_loss: 0.0460\n",
      "Epoch 92/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.9875 - val_loss: 0.0391\n",
      "Epoch 93/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9906 - val_loss: 0.0297\n",
      "Epoch 94/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.8819 - val_loss: 0.4069\n",
      "Epoch 95/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0129 - val_accuracy: 0.9969 - val_loss: 0.0107\n",
      "Epoch 96/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0068 - val_accuracy: 0.9833 - val_loss: 0.0558\n",
      "Epoch 97/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 0.9969 - val_loss: 0.0139\n",
      "Epoch 98/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0201 - val_accuracy: 0.9937 - val_loss: 0.0210\n",
      "Epoch 99/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9723 - val_loss: 0.0902\n",
      "Epoch 100/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0181 - val_accuracy: 0.9906 - val_loss: 0.0301\n",
      "Epoch 101/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0231 - val_accuracy: 0.9864 - val_loss: 0.0494\n",
      "Epoch 102/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0183 - val_accuracy: 0.9963 - val_loss: 0.0113\n",
      "Epoch 103/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0210 - val_accuracy: 0.9984 - val_loss: 0.0071\n",
      "Epoch 104/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0200 - val_accuracy: 0.9592 - val_loss: 0.1447\n",
      "Epoch 105/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0153 - val_accuracy: 0.9942 - val_loss: 0.0191\n",
      "Epoch 106/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9927 - val_loss: 0.0198\n",
      "Epoch 107/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0147 - val_accuracy: 0.9885 - val_loss: 0.0421\n",
      "Epoch 108/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0148 - val_accuracy: 0.9895 - val_loss: 0.0438\n",
      "Epoch 109/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0080 - val_accuracy: 0.9927 - val_loss: 0.0316\n",
      "Epoch 110/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9942 - val_loss: 0.0162\n",
      "Epoch 111/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0147 - val_accuracy: 0.9801 - val_loss: 0.0853\n",
      "Epoch 112/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0155 - val_accuracy: 0.9880 - val_loss: 0.0396\n",
      "Epoch 113/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0212 - val_accuracy: 0.9963 - val_loss: 0.0121\n",
      "Epoch 114/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9880 - val_loss: 0.0492\n",
      "Epoch 115/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0173 - val_accuracy: 0.9937 - val_loss: 0.0145\n",
      "Epoch 116/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0169 - val_accuracy: 0.9948 - val_loss: 0.0166\n",
      "Epoch 117/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0086 - val_accuracy: 0.9922 - val_loss: 0.0339\n",
      "Epoch 118/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0137 - val_accuracy: 0.9744 - val_loss: 0.0840\n",
      "Epoch 119/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9963 - val_loss: 0.0218\n",
      "Epoch 120/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0191 - val_accuracy: 0.9880 - val_loss: 0.0409\n",
      "Epoch 121/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0115 - val_accuracy: 0.9875 - val_loss: 0.0385\n",
      "Epoch 122/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0113 - val_accuracy: 0.9812 - val_loss: 0.0489\n",
      "Epoch 123/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9990 - val_loss: 0.0081\n",
      "Epoch 124/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0161 - val_accuracy: 0.9927 - val_loss: 0.0242\n",
      "Epoch 125/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0117 - val_accuracy: 0.9963 - val_loss: 0.0073\n",
      "Epoch 126/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.7585 - val_loss: 0.7513\n",
      "Epoch 127/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0117 - val_accuracy: 0.9974 - val_loss: 0.0059\n",
      "Epoch 128/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.9415 - val_loss: 0.1419\n",
      "Epoch 129/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9326 - val_loss: 0.1549\n",
      "Epoch 130/150\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0127 - val_accuracy: 0.9953 - val_loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:52:52,876 - INFO - Saved model to results\\sample_dataMalaria2024\\bacon_classification\\experiment_1cdc8d05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:52:53,497 - INFO - Metrics saved to results\\sample_dataMalaria2024\\bacon_classification\\experiment_1cdc8d05\\metrics.json\n",
      "2024-10-31 11:52:53,498 - INFO - Evaluation Metrics: {'accuracy': 0.954863813229572}\n",
      "2024-10-31 11:52:53,501 - INFO - Predictions saved to results\\sample_dataMalaria2024\\bacon_classification\\experiment_1cdc8d05\\predictions.csv\n",
      "2024-10-31 11:52:53,503 - INFO - Updated experiments at results\\sample_dataMalaria2024\\bacon_classification\\experiments.json\n",
      "2024-10-31 11:52:53,509 - INFO - Updated experiments at results\\sample_dataMalaria2024\\experiments.json\n",
      "2024-10-31 11:52:53,510 - INFO - Updated experiments at results\\sample_dataMalaria2024\\bacon_classification\\experiments.json and results\\sample_dataMalaria2024\\experiments.json\n",
      "2024-10-31 11:52:53,511 - INFO - All experiments completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 267.39717745780945 seconds\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "import time\n",
    "from pinard.presets.ref_models import decon, bacon, customizable_bacon, bacon_classification\n",
    "from pinard.presets.preprocessings import decon_set, bacon_set\n",
    "from pinard.data_splitters import KennardStoneSplitter\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS, Derivate as  Dv\n",
    "from pinard.transformations import Rotate_Translate as RT, Spline_X_Simplification as SXS, Random_X_Operation as RXO\n",
    "from pinard.transformations import CropTransformer\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, ShuffleSplit, GroupKFold, StratifiedShuffleSplit, BaseCrossValidator, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "model_sklearn = {\n",
    "    \"class\": \"sklearn.cross_decomposition.PLSRegression\",\n",
    "    \"model_params\": {\n",
    "        \"n_components\": 21,\n",
    "    }\n",
    "}\n",
    "    \n",
    "finetune_pls_experiment = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_components': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "bacon_train = {\"action\": \"train\", \"training_params\": {\"epochs\": 2000, \"batch_size\": 500, \"patience\": 200, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 400}}\n",
    "bacon_train_short = {\"action\": \"train\", \"training_params\": {\"epochs\": 10, \"batch_size\": 500, \"patience\": 20, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 40}}\n",
    "bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    "}\n",
    "\n",
    "full_bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 500,\n",
    "        \"patience\": 100,\n",
    "    },\n",
    "    \"finetune_params\": {\n",
    "        \"nb_trials\": 150,\n",
    "        \"model_params\": {\n",
    "            'spatial_dropout': (float, 0.01, 0.5),\n",
    "            'filters1': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'kernel_size1': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides1': [1, 2, 3, 4, 5],\n",
    "            # 'activation1': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'dropout_rate': (float, 0.01, 0.5),\n",
    "            'filters2': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size2': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides2': [1, 2, 3, 4, 5],\n",
    "            'activation2': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'normalization_method1': ['BatchNormalization', 'LayerNormalization'],\n",
    "            'filters3': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size3': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides3': [1, 2, 3, 4, 5],\n",
    "            'activation3': ['relu', 'selu', 'elu', 'swish'],\n",
    "            # 'normalization_method2': ['BatchNormalization', 'LayerNormalization'],\n",
    "            # 'dense_units': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'dense_activation': ['relu', 'selu', 'elu', 'swish'],\n",
    "        },\n",
    "        # \"training_params\": {\n",
    "        #     \"batch_size\": [32, 64, 128, 256, 512],\n",
    "        #     \"cyclic_lr\": [True, False],\n",
    "        #     \"base_lr\": (float, 1e-6, 1e-2),\n",
    "        #     \"max_lr\": (float, 1e-3, 1e-1),\n",
    "        #     \"step_size\": (int, 500, 5000),\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "x_pipeline_PLS = [\n",
    "    RobustScaler(),\n",
    "    # {\"samples\": [None, SXS, RXO]},\n",
    "    # {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "                    \n",
    "\n",
    "\n",
    "x_pipeline_full = [\n",
    "    RobustScaler(),\n",
    "    {\"samples\": [None, None,None,None,SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipeline_full2 = [\n",
    "    RobustScaler(),\n",
    "    {\"samples\": [None, None,None,None,SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipeline = [\n",
    "    RobustScaler(), \n",
    "    # {\"samples\": [None, SXS]}, \n",
    "    {\"samples\": [RT], \"balance\": True},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    {\"features\": [None, [GS(), SNV()], SG(), GS()]}, \n",
    "    # {\"features\": [None, GS]}, \n",
    "    # {\"features\": [None, GS, SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    # {\"features\": [None, SG, GS, SNV, [SG, SNV], [GS, SNV], [SG, GS]]}, \n",
    "    # bacon_set(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "bacon_finetune_classif = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 5,\n",
    "    }\n",
    "}\n",
    "\n",
    "finetune_randomForestclassifier = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_estimators': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "seed = 123459456\n",
    "\n",
    "datasets = \"sample_data/mock_data3_classif\"\n",
    "y_pipeline = MinMaxScaler()\n",
    "# processing only\n",
    "config1 = Config(\"sample_data/Malaria2024\", x_pipeline_full, y_pipeline, None, None, seed)\n",
    "## TRAINING\n",
    "# regression\n",
    "config2 = Config(\"sample_data/mock_data2\", x_pipeline, y_pipeline, bacon, bacon_train_short, seed)\n",
    "config3 = Config(\"sample_data/mock_data3\", x_pipeline_PLS, y_pipeline, model_sklearn, None, seed)\n",
    "# classification\n",
    "config4 = Config(\"sample_data/Malaria2024\", x_pipeline, None, bacon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":150}}, seed*2)\n",
    "config5 = Config(\"sample_data/mock_data3_binary\", x_pipeline, None, bacon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":5}}, seed*2)\n",
    "config6 = Config(\"sample_data/WhiskyConcentration\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "config7 = Config(\"sample_data/Malaria2024\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "## FINETUNING\n",
    "# regression\n",
    "config8 = Config(\"sample_data/mock_data3\", x_pipeline, y_pipeline, bacon, bacon_finetune, seed)\n",
    "config9 = Config(\"sample_data/mock_data3\", x_pipeline, y_pipeline, model_sklearn, finetune_pls_experiment, seed)\n",
    "# classification\n",
    "config10 = Config(\"sample_data/mock_data3_classif\", x_pipeline, None, bacon_classification, bacon_finetune_classif, seed*2)\n",
    "config11 = Config(\"sample_data/mock_data3_classif\", x_pipeline, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "\n",
    "\n",
    "# configs = [config1, config2, config3, config4, config5, config6, config7]\n",
    "# configs = [config8, config9, config10, config11]\n",
    "configs = [config4]\n",
    "\n",
    "start = time.time()\n",
    "runner = ExperimentRunner(configs, resume_mode=\"restart\")\n",
    "dataset, model_manager = runner.run()\n",
    "end = time.time()\n",
    "print(f\"Time elapsed: {end-start} seconds\")\n",
    "\n",
    "\n",
    "# print(dataset)\n",
    "# print(dataset.raw_x_train.shape)\n",
    "# print(dataset.to_str(\"union\"))\n",
    "\n",
    "\n",
    "# # chart all sample transformations\n",
    "# sample_0 = dataset.x_train[0][0]\n",
    "# print(sample_0.shape)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# fig, axs = plt.subplots(5, 5, figsize=(15, 5))\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.plot(sample_0[i])\n",
    "#     ax.set_title(f\"Sample {i}\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# class AddVal(TransformerMixin, BaseEstimator):\n",
    "#     def __init__(self, val):\n",
    "#         self.val = val\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return X + self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:56:09,971 - INFO - ================================================================================\n",
      "2024-10-31 11:56:09,972 - INFO - ### PREPARING DATA ###\n",
      "2024-10-31 11:56:09,973 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0b1\n",
      ">> Browsing sample_data/Malaria2024\n",
      "No train_group file found for sample_data/Malaria2024.\n",
      "No test_group file found for sample_data/Malaria2024.\n",
      "{'initial_shape': (2996, 1665), 'delimiter': ';', 'numeric_delimiter': '.', 'header_line': 0, 'final_shape': (2996, 1665), 'na_handling': {'strategy': 'abort', 'nb_removed_rows': None, 'removed_rows': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:56:12,191 - INFO - Dataset(x_train:(2996, 1665) - y_train:(2996, 1), x_test:(1285, 1665) - y_test:(1285, 1))\n",
      "2024-10-31 11:56:12,191 - INFO - ### PROCESSING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_shape': (1285, 1665), 'delimiter': ';', 'numeric_delimiter': '.', 'header_line': 0, 'final_shape': (1285, 1665), 'na_handling': {'strategy': 'abort', 'nb_removed_rows': None, 'removed_rows': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 11:56:18,659 - INFO - Dataset(x_train:(17976, 18315) - y_train:(17976, 1), x_test:(1285, 18315) - y_test:(1285, 1))\n",
      "Folds size: 1997-999, 1997-999, 1998-998\n",
      "2024-10-31 11:56:18,660 - INFO - ### PREPARING MODEL ###\n",
      "2024-10-31 11:56:18,661 - INFO - Running config > {'dataset': 'sample_data/Malaria2024', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'samples': [None, None, None, None, {'class': 'pinard.transformations.Spline_X_Simplification', 'params': None}, {'class': 'pinard.transformations.Random_X_Operation', 'params': None}]}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'features': [None, {'class': 'pinard.transformations.Gaussian', 'params': {'copy': True, 'order': 2, 'sigma': 1}}, {'class': 'pinard.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}, {'class': 'pinard.transformations.Derivate', 'params': None}, [{'class': 'pinard.transformations.Gaussian', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'pinard.transformations.Gaussian', 'params': None}, {'class': 'pinard.transformations.Gaussian', 'params': None}], [{'class': 'pinard.transformations.Gaussian', 'params': None}, {'class': 'pinard.transformations.SavitzkyGolay', 'params': None}], [{'class': 'pinard.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'pinard.transformations.Gaussian', 'params': None}, {'class': 'pinard.transformations.Derivate', 'params': None}], [{'class': 'pinard.transformations.SavitzkyGolay', 'params': None}, {'class': 'pinard.transformations.Derivate', 'params': None}]]}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': None, 'experiment': {'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2024-10-31 11:56:18,663 - INFO - Starting new experiment experiment_a2212c52.\n",
      "2024-10-31 11:56:18,664 - INFO - Experiment prepared at results\\sample_dataMalaria2024\\unknown_model\\experiment_a2212c52\n",
      "2024-10-31 11:56:18,665 - INFO - All experiments completed.\n"
     ]
    }
   ],
   "source": [
    "import pinard\n",
    "print(pinard.__version__)\n",
    "\n",
    "# load malaria manually and apply RT transformation manually and display chart of transformed samples\n",
    "\n",
    "config1 = Config(\"sample_data/Malaria2024\", x_pipeline, y_pipeline, None, None, seed)\n",
    "runner = ExperimentRunner([config1], resume_mode=\"restart\")\n",
    "dataset, model_manager = runner.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ace_tools as tools\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn metrics list\n",
    "sklearn_metrics = [\n",
    "    \"explained_variance\", \"r2\", \"max_error\", \"matthews_corrcoef\",\n",
    "    \"neg_median_absolute_error\", \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\", \"neg_mean_squared_error\",\n",
    "    \"neg_mean_squared_log_error\", \"neg_root_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_log_error\", \"neg_mean_poisson_deviance\",\n",
    "    \"neg_mean_gamma_deviance\", \"d2_absolute_error_score\", \"accuracy\",\n",
    "    \"top_k_accuracy\", \"roc_auc\", \"roc_auc_ovr\", \"roc_auc_ovo\",\n",
    "    \"roc_auc_ovr_weighted\", \"roc_auc_ovo_weighted\", \"balanced_accuracy\",\n",
    "    \"average_precision\", \"neg_log_loss\", \"neg_brier_score\",\n",
    "    \"positive_likelihood_ratio\", \"neg_negative_likelihood_ratio\",\n",
    "    \"adjusted_rand_score\", \"rand_score\", \"homogeneity_score\",\n",
    "    \"completeness_score\", \"v_measure_score\", \"mutual_info_score\",\n",
    "    \"adjusted_mutual_info_score\", \"normalized_mutual_info_score\",\n",
    "    \"fowlkes_mallows_score\"\n",
    "]\n",
    "\n",
    "# Tensorflow/keras metrics list\n",
    "tensorflow_metrics = [\n",
    "    \"MeanSquaredError\", \"RootMeanSquaredError\", \"MeanAbsoluteError\",\n",
    "    \"MeanAbsolutePercentageError\", \"MeanSquaredLogarithmicError\",\n",
    "    \"CosineSimilarity\", \"LogCoshError\", \"R2Score\", \"AUC\",\n",
    "    \"FalseNegatives\", \"FalsePositives\", \"Precision\", \"PrecisionAtRecall\",\n",
    "    \"Recall\", \"RecallAtPrecision\", \"SensitivityAtSpecificity\",\n",
    "    \"SpecificityAtSensitivity\", \"TrueNegatives\", \"TruePositives\",\n",
    "    \"Hinge\", \"SquaredHinge\", \"CategoricalHinge\", \"KLDivergence\",\n",
    "    \"Poisson\", \"BinaryCrossentropy\", \"CategoricalCrossentropy\",\n",
    "    \"SparseCategoricalCrossentropy\", \"Accuracy\", \"BinaryAccuracy\",\n",
    "    \"CategoricalAccuracy\", \"SparseCategoricalAccuracy\",\n",
    "    \"TopKCategoricalAccuracy\", \"SparseTopKCategoricalAccuracy\",\n",
    "    \"F1Score\", \"FBetaScore\", \"IoU\", \"BinaryIoU\", \"MeanIoU\",\n",
    "    \"OneHotIoU\", \"OneHotMeanIoU\"\n",
    "]\n",
    "\n",
    "# Metric name mapping: (tensorflow_name, sklearn_name, abbreviation, method_name)\n",
    "# Initialize with common names\n",
    "metrics_mapping = [\n",
    "    (\"MeanSquaredError\", \"neg_mean_squared_error\", \"mse\", \"Mean Squared Error\"),\n",
    "    (\"RootMeanSquaredError\", \"neg_root_mean_squared_error\", \"rmse\", \"Root Mean Squared Error\"),\n",
    "    (\"MeanAbsoluteError\", \"neg_mean_absolute_error\", \"mae\", \"Mean Absolute Error\"),\n",
    "    (\"MeanAbsolutePercentageError\", \"neg_mean_absolute_percentage_error\", \"mape\", \"Mean Absolute Percentage Error\"),\n",
    "    (\"MeanSquaredLogarithmicError\", \"neg_mean_squared_log_error\", \"msle\", \"Mean Squared Logarithmic Error\"),\n",
    "    (\"CosineSimilarity\", None, \"cos_sim\", \"Cosine Similarity\"),\n",
    "    (\"LogCoshError\", None, \"log_cosh\", \"Log Cosh Error\"),\n",
    "    (\"R2Score\", \"r2\", \"r2\", \"R2 Score\"),\n",
    "    (\"AUC\", \"roc_auc\", \"auc\", \"Area Under the Curve\"),\n",
    "    (\"Precision\", None, \"prec\", \"Precision\"),\n",
    "    (\"Recall\", None, \"recall\", \"Recall\"),\n",
    "    (\"Accuracy\", \"accuracy\", \"acc\", \"Accuracy\"),\n",
    "    (\"TopKCategoricalAccuracy\", \"top_k_accuracy\", \"top_k_acc\", \"Top K Categorical Accuracy\"),\n",
    "    (\"BinaryCrossentropy\", None, \"bin_crossentropy\", \"Binary Crossentropy\"),\n",
    "    (\"CategoricalCrossentropy\", None, \"cat_crossentropy\", \"Categorical Crossentropy\"),\n",
    "    (\"SparseCategoricalCrossentropy\", None, \"sparse_cat_crossentropy\", \"Sparse Categorical Crossentropy\"),\n",
    "    (\"F1Score\", None, \"f1\", \"F1 Score\"),\n",
    "    (\"IoU\", None, \"iou\", \"Intersection over Union\")\n",
    "]\n",
    "\n",
    "# Add remaining metrics with None in the missing columns\n",
    "for metric in sklearn_metrics:\n",
    "    if not any(metric in row for row in metrics_mapping):\n",
    "        metrics_mapping.append((None, metric, None, None))\n",
    "\n",
    "for metric in tensorflow_metrics:\n",
    "    if not any(metric in row for row in metrics_mapping):\n",
    "        metrics_mapping.append((metric, None, None, None))\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(metrics_mapping, columns=[\"tensorflow_name\", \"sklearn_name\", \"abbreviation\", \"method_name\"])\n",
    "\n",
    "# Display the dataframe to the user\n",
    "tools.display_dataframe_to_user(name=\"Metric Comparison\", dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Applying a Simple Data Transformation using Pinard\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline\n",
    "# Here we apply Standard Normal Variate (SNV) transformation\n",
    "x_pipeline = [\n",
    "    SNV(),            # Apply SNV transformation\n",
    "    MinMaxScaler()    # Scale features to [0,1]\n",
    "]\n",
    "\n",
    "# No model is used in this example; we focus on data transformation\n",
    "config = Config(\n",
    "    dataset_path,\n",
    "    x_pipeline,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Access the transformed data\n",
    "transformed_data = dataset.x_train\n",
    "\n",
    "print(\"Transformed data shape:\", transformed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Applying a Preprocessing Pipeline and Training a Simple Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline\n",
    "x_pipeline = [\n",
    "    SG(window_length=11, polyorder=2),  # Apply Savitzky-Golay filter\n",
    "    SNV(),                              # Apply SNV transformation\n",
    "    MinMaxScaler()                      # Scale features to [0,1]\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.linear_model.LinearRegression\",\n",
    "    \"model_params\": {}\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "train_params = {\n",
    "    \"action\": \"train\",\n",
    "    \"training_params\": {}\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=train_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Access the trained model\n",
    "trained_model = model_manager.models[0].model\n",
    "\n",
    "# Print model coefficients\n",
    "print(\"Model coefficients:\", trained_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Using Cross-Validation with Pinard\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline with cross-validation\n",
    "x_pipeline = [\n",
    "    {\"split\": RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)},\n",
    "    SG(window_length=11, polyorder=2),\n",
    "    SNV(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.linear_model.Ridge\",\n",
    "    \"model_params\": {\n",
    "        \"alpha\": 1.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "train_params = {\n",
    "    \"action\": \"train\",\n",
    "    \"training_params\": {}\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=train_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model_manager.models[0].scores\n",
    "print(\"Cross-validation scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Fine-tuning a Model with Pinard\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline with cross-validation\n",
    "x_pipeline = [\n",
    "    {\"split\": RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)},\n",
    "    SG(window_length=11, polyorder=2),\n",
    "    SNV(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.linear_model.Ridge\",\n",
    "    \"model_params\": {}\n",
    "}\n",
    "\n",
    "# Define the finetune parameters\n",
    "finetune_params = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'alpha': ('float', 0.1, 10.0)\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'n_trials': 20,\n",
    "        'tuner': 'sklearn'  # Use scikit-learn's GridSearchCV\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=finetune_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = model_manager.models[0].best_model\n",
    "best_params = model_manager.models[0].best_params\n",
    "\n",
    "print(\"Best model parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Fine-tuning a Model with Pinard\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline with cross-validation\n",
    "x_pipeline = [\n",
    "    {\"split\": RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)},\n",
    "    SG(window_length=11, polyorder=2),\n",
    "    SNV(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.linear_model.Ridge\",\n",
    "    \"model_params\": {}\n",
    "}\n",
    "\n",
    "# Define the finetune parameters\n",
    "finetune_params = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'alpha': ('float', 0.1, 10.0)\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'n_trials': 20,\n",
    "        'tuner': 'sklearn'  # Use scikit-learn's GridSearchCV\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=finetune_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = model_manager.models[0].best_model\n",
    "best_params = model_manager.models[0].best_params\n",
    "\n",
    "print(\"Best model parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Fine-tuning a Custom TensorFlow Model with Pinard\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pinard.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Placeholder for input shape (to be defined later)\n",
    "input_shape = None\n",
    "\n",
    "# Define a hypermodel for Keras Tuner\n",
    "\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "        units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "        model.add(tf.keras.layers.Dense(units=units, activation='relu', input_shape=(input_shape,)))\n",
    "        model.add(tf.keras.layers.Dense(1))\n",
    "        optimizer = hp.Choice('optimizer', ['adam', 'sgd'])\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        return model\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"tensorflow.keras.models.Sequential\",\n",
    "    \"model_params\": {\n",
    "        \"build_fn\": MyHyperModel()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the finetune parameters\n",
    "finetune_params = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'units': ('int', 32, 128, 32),\n",
    "            'optimizer': ['adam', 'sgd']\n",
    "        },\n",
    "        'training_params': {\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32\n",
    "        },\n",
    "        'n_trials': 20,\n",
    "        'tuner': 'keras'  # Use Keras Tuner\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the data transformation pipeline with cross-validation\n",
    "x_pipeline = [\n",
    "    {\"split\": RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)},\n",
    "    SG(window_length=11, polyorder=2),\n",
    "    SNV(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=finetune_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "\n",
    "# Set the input shape after data is loaded\n",
    "dataset, model_manager = runner.load_data_only()\n",
    "input_shape = dataset.x_train.shape[1]\n",
    "model['model_params']['build_fn'] = MyHyperModel()\n",
    "\n",
    "# Run the finetuning\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = model_manager.models[0].best_model\n",
    "best_params = model_manager.models[0].best_params\n",
    "\n",
    "print(\"Best model parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class LogTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Applies a logarithmic transformation to the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, copy=True, offset=1e-6):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        copy : bool, default=True\n",
    "            Set to False to perform inplace computation.\n",
    "        offset : float, default=1e-6\n",
    "            A small constant to add to the data to avoid log(0).\n",
    "        \"\"\"\n",
    "        self.copy = copy\n",
    "        self.offset = offset\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"\n",
    "        Apply the logarithmic transformation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The data to transform.\n",
    "        copy : bool, default=None\n",
    "            Copy the input X or not.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : array-like of shape (n_samples, n_features)\n",
    "            Transformed data.\n",
    "        \"\"\"\n",
    "        if copy is None:\n",
    "            copy = self.copy\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        if copy:\n",
    "            X = X.copy()\n",
    "\n",
    "        X = np.log(X + self.offset)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.utils import check_random_state\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StratifiedFeatureSplitter(BaseCrossValidator):\n",
    "    \"\"\"\n",
    "    Stratified splitter based on a continuous feature.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5, feature_index=0, random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_splits : int, default=5\n",
    "            Number of folds.\n",
    "        feature_index : int, default=0\n",
    "            Index of the feature to stratify on.\n",
    "        random_state : int or RandomState instance, default=None\n",
    "            Random state for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.feature_index = feature_index\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        X = np.asarray(X)\n",
    "        feature = X[:, self.feature_index]\n",
    "        percentiles = np.percentile(feature, np.linspace(0, 100, self.n_splits + 1))\n",
    "\n",
    "        indices = np.arange(len(X))\n",
    "        rng = check_random_state(self.random_state)\n",
    "        rng.shuffle(indices)\n",
    "\n",
    "        bins = np.digitize(feature[indices], percentiles[1:-1], right=True)\n",
    "\n",
    "        for fold in range(self.n_splits):\n",
    "            test_mask = bins == fold\n",
    "            train_mask = ~test_mask\n",
    "            yield indices[train_mask], indices[test_mask]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Custom LogTransformer and StratifiedFeatureSplitter in Pinard\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Assuming LogTransformer and StratifiedFeatureSplitter are defined as above\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline\n",
    "x_pipeline = [\n",
    "    {\"split\": StratifiedFeatureSplitter(n_splits=5, feature_index=0, random_state=42)},\n",
    "    LogTransformer(offset=1e-6),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.linear_model.LinearRegression\",\n",
    "    \"model_params\": {}\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "train_params = {\n",
    "    \"action\": \"train\",\n",
    "    \"training_params\": {}\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=train_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Access the trained model\n",
    "trained_model = model_manager.models[0].model\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "y_pred = trained_model.predict(dataset.x_test)\n",
    "mse = mean_squared_error(dataset.y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatioTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Creates a new feature by taking the ratio of two features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numerator_index=0, denominator_index=1, copy=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        numerator_index : int, default=0\n",
    "            Index of the numerator feature.\n",
    "        denominator_index : int, default=1\n",
    "            Index of the denominator feature.\n",
    "        copy : bool, default=True\n",
    "            Set to False to perform inplace computation.\n",
    "        \"\"\"\n",
    "        self.numerator_index = numerator_index\n",
    "        self.denominator_index = denominator_index\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"\n",
    "        Create a new feature as the ratio of two existing features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The data to transform.\n",
    "        copy : bool, default=None\n",
    "            Copy the input X or not.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : array-like of shape (n_samples, n_features + 1)\n",
    "            Transformed data with the new ratio feature added.\n",
    "        \"\"\"\n",
    "        if copy is None:\n",
    "            copy = self.copy\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        if copy:\n",
    "            X = X.copy()\n",
    "\n",
    "        numerator = X[:, self.numerator_index]\n",
    "        denominator = X[:, self.denominator_index] + 1e-6  # Avoid division by zero\n",
    "        ratio_feature = (numerator / denominator).reshape(-1, 1)\n",
    "\n",
    "        X_new = np.hstack((X, ratio_feature))\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "\n",
    "class ClusterBasedSplitter(BaseCrossValidator):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5, n_clusters=5, random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_splits : int, default=5\n",
    "            Number of splits/folds.\n",
    "        n_clusters : int, default=5\n",
    "            Number of clusters to form.\n",
    "        random_state : int or RandomState instance, default=None\n",
    "            Random state for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        X = np.asarray(X)\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=self.random_state)\n",
    "        cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "        unique_clusters = np.unique(cluster_labels)\n",
    "        rng = check_random_state(self.random_state)\n",
    "        rng.shuffle(unique_clusters)\n",
    "\n",
    "        clusters_per_split = np.array_split(unique_clusters, self.n_splits)\n",
    "\n",
    "        for cluster_group in clusters_per_split:\n",
    "            test_indices = np.where(np.isin(cluster_labels, cluster_group))[0]\n",
    "            train_indices = np.setdiff1d(np.arange(len(X)), test_indices)\n",
    "            yield train_indices, test_indices\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Custom ClusterBasedSplitter in Pinard\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pinard.core.runner import ExperimentRunner\n",
    "from pinard.core.config import Config\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "\n",
    "# Assuming ClusterBasedSplitter is defined as above\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"sample_data/mock_data\"\n",
    "\n",
    "# Define the data transformation pipeline\n",
    "x_pipeline = [\n",
    "    StandardScaler(),\n",
    "    {\"split\": ClusterBasedSplitter(n_splits=5, n_clusters=5, random_state=42)}\n",
    "]\n",
    "\n",
    "# Define the model\n",
    "model = {\n",
    "    \"class\": \"sklearn.svm.SVR\",\n",
    "    \"model_params\": {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"C\": 1.0,\n",
    "        \"epsilon\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "train_params = {\n",
    "    \"action\": \"train\",\n",
    "    \"training_params\": {}\n",
    "}\n",
    "\n",
    "# Define the configuration\n",
    "config = Config(\n",
    "    dataset_path=dataset_path,\n",
    "    x_pipeline=x_pipeline,\n",
    "    y_pipeline=None,\n",
    "    model=model,\n",
    "    experiment_params=train_params,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "runner = ExperimentRunner(configs=[config])\n",
    "dataset, model_manager = runner.run()\n",
    "\n",
    "# Access the trained model\n",
    "trained_model = model_manager.models[0].model\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "y_pred = trained_model.predict(dataset.x_test)\n",
    "mse = mean_squared_error(dataset.y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
