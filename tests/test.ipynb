{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinard.model_selection import train_test_split_idx\n",
    "import numpy as np\n",
    "from os.path import abspath\n",
    "from os.path import dirname as d\n",
    "\n",
    "ROOT_DIR = './..'\n",
    "\n",
    "\n",
    "def path_to(str):\n",
    "    return ROOT_DIR + \"/tests/data/\" + str\n",
    "\n",
    "\n",
    "def split_data():\n",
    "    split_data = np.loadtxt(path_to(\"test_split.csv\"), delimiter=\";\")\n",
    "    y = np.reshape(split_data[:, 0], (-1, 1))\n",
    "    x = split_data[:, 1:]\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def split_validation_data():\n",
    "    split_validation_data = np.loadtxt(\n",
    "        path_to(\"test_split_validation.csv\"), delimiter=\";\"\n",
    "    )\n",
    "    return split_validation_data.astype(int)\n",
    "\n",
    "\n",
    "split_list = [\n",
    "    ({\"method\": \"random\", \"test_size\": 0.25, \"random_state\": 42}, 0),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        1,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"pca_components\": 4,\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        2,\n",
    "    ),\n",
    "    ({\"method\": \"kennard_stone\", \"test_size\": 0.25, \"random_state\": 42}, 3),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "            \"pca_components\": 8,\n",
    "        },\n",
    "        4,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "        },\n",
    "        5,\n",
    "    ),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42}, 6),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"pca_components\": 2}, 7),\n",
    "    (\n",
    "        {\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"metric\": \"canberra\"},\n",
    "        8,\n",
    "    ),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42}, 9),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42, \"n_bins\": 4}, 10),\n",
    "    ({\"method\": \"circular\", \"test_size\": 0.25, \"random_state\": 42}, 11),\n",
    "]\n",
    "\n",
    "\n",
    "x, y = split_data()\n",
    "index = 2\n",
    "opt = split_list[index][0]\n",
    "train_index, _ = train_test_split_idx(x, y=y, **opt)\n",
    "np.savetxt(\n",
    "    \"alidation.csv\", train_index, delimiter=\";\", fmt=\"%d\"\n",
    ")\n",
    "split_validation_data = split_validation_data()\n",
    "# print(list(zip(train_index, split_validation_data[:, index])))\n",
    "np.testing.assert_array_equal(train_index, split_validation_data[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Rotate_Translate\n",
      "Rotate_Translate_custom\n",
      "Random_X_Operation\n",
      "Random_X_Operation_custom\n",
      "Spline_Smoothing\n",
      "(4, 234) (4, 234)\n",
      "(4, 234) (4, 234)\n",
      "Spline_X_Perturbation\n",
      "Spline_X_Perturbation\n",
      "Spline_Y_Perturbation\n",
      "Spline_Y_Perturbation\n",
      "Spline_X_Simplification\n",
      "Spline_X_Simplification\n",
      "Spline_Curve_Simplification\n",
      "Spline_Curve_Simplification\n",
      "Spline_Curve_Simplification\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import operator\n",
    "import pinard\n",
    "import pinard.augmentation as aug\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "importlib.reload(pinard.augmentation)\n",
    "importlib.reload(aug)\n",
    "\n",
    "# def augment(X, apply_on=\"samples\"):\n",
    "#     x = np.arange(0, len(X[0]), 1)\n",
    "#     t, c, k = interpolate.splrep(x, X[0], s=0, k=3)\n",
    "#     delta_x_size = int(np.around(len(t) / 20))\n",
    "#     delta_x = np.linspace(np.min(x), np.max(x), delta_x_size)\n",
    "#     delta_y = np.random.uniform(-10, 10, delta_x_size)\n",
    "#     delta = np.interp(t, delta_x, delta_y)\n",
    "#     t = t + delta\n",
    "#     spline = interpolate.BSpline(t, c, k, extrapolate=True)\n",
    "\n",
    "#     return spline(X)\n",
    "\n",
    "\n",
    "def split_data():\n",
    "    split_data = np.loadtxt(\"data/test_augmentation.csv\", delimiter=\";\")\n",
    "    y = np.reshape(split_data[:, 0], (-1, 1))\n",
    "    x = split_data[:, 1:]\n",
    "    return (x, y)\n",
    "\n",
    "seed = 42\n",
    "augmenters = [\n",
    "    (0, \"Rotate_Translate\", aug.Rotate_Translate, {\"random_state\":seed}),\n",
    "    (1, \"Rotate_Translate_custom\", aug.Rotate_Translate,{\"random_state\": seed, \"p_range\": 5, \"y_factor\": 5}),\n",
    "    (2, \"Random_X_Operation\", aug.Random_X_Operation, {\"random_state\": seed}),\n",
    "    (3, \"Random_X_Operation_custom\", aug.Random_X_Operation, {\"random_state\": seed, \"operator_func\": operator.add, \"operator_range\": (-0.002, 0.002)}),\n",
    "    (4, \"Spline_Smoothing\", aug.Spline_Smoothing, {\"random_state\": seed}),\n",
    "    (5, \"Spline_X_Perturbation\", aug.Spline_X_Perturbations, {\"random_state\": seed}),\n",
    "    (6, \"Spline_X_Perturbation\", aug.Spline_X_Perturbations, {\"random_state\": seed, \"perturbation_density\":0.01, \"perturbation_range\":(-30, 30)}),\n",
    "    (7, \"Spline_Y_Perturbation\", aug.Spline_Y_Perturbations, {\"random_state\": seed}),\n",
    "    (8, \"Spline_Y_Perturbation\", aug.Spline_Y_Perturbations, {\"random_state\": seed, \"spline_points\":5, \"perturbation_intensity\":0.02}),\n",
    "    (9, \"Spline_X_Simplification\", aug.Spline_X_Simplification, {\"random_state\": seed}),\n",
    "    (10, \"Spline_X_Simplification\", aug.Spline_X_Simplification, {\"random_state\": seed, \"spline_points\":15}),\n",
    "    (11, \"Spline_Curve_Simplification\", aug.Spline_Curve_Simplification, {\"random_state\": seed}),\n",
    "    (12, \"Spline_Curve_Simplification\", aug.Spline_Curve_Simplification, {\"random_state\": seed, \"spline_points\":5, \"uniform\":False}),\n",
    "    (13, \"Spline_Curve_Simplification\", aug.Spline_Curve_Simplification, {\"random_state\": seed, \"spline_points\":5, \"uniform\":True}),\n",
    "]\n",
    "\n",
    "X, Y = split_data()\n",
    "\n",
    "for index, name, augmenter, params in augmenters:\n",
    "    print(name)\n",
    "    aug_instance = augmenter(**params)\n",
    "    augmented_X = aug_instance.augment(X, apply_on=\"global\")\n",
    "    augmented_X = np.savetxt(f\"data/test_augmentation_{index}_{name}_global.csv\", augmented_X, delimiter=\";\", fmt=\"%.3f\")\n",
    "    \n",
    "    aug_instance = augmenter(**params)\n",
    "    augmented_X = aug_instance.augment(X, apply_on=\"samples\")\n",
    "    augmented_X = np.savetxt(f\"data/test_augmentation_{index}_{name}_samples.csv\", augmented_X, delimiter=\";\", fmt=\"%.3f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_json_combinations(json_data, depth=0, max_depth=7):\n",
    "    if depth > max_depth:\n",
    "        return []\n",
    "    if isinstance(json_data, list):\n",
    "        combinations = []\n",
    "        for item in json_data:\n",
    "            combinations.extend(generate_json_combinations(item, depth + 1, max_depth))\n",
    "        return combinations\n",
    "    elif isinstance(json_data, dict):\n",
    "        combinations = []\n",
    "        for key, value in json_data.items():\n",
    "            combinations.extend(generate_json_combinations(value, depth + 1, max_depth))\n",
    "        return combinations\n",
    "    else:\n",
    "        return [json_data]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_json = {\n",
    "    \"key1\": \"my_task\",\n",
    "    \"key2\": {\"*\": [\"my_task2\", \"my_task2_alt\"]},\n",
    "    \"key3\": [\"pipeline_task1\", {\"*\": [\"pipeline_task2\", {\"*\": [\"pipeline_task4\", \"pipeline_task4_alt\"]}]}, \"pipeline_task3\"],\n",
    "    \"*\": [{\"key5\": \"task5\", \"key6\": \"task6\"}, {\"key5_alt\": \"task5_alt\"}]\n",
    "}\n",
    "\n",
    "# Call the function and print the generated JSON objects\n",
    "generated_json_objects = generate_json_combinations(input_json)\n",
    "for obj in generated_json_objects:\n",
    "    print(json.dumps(obj, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example NumPy array\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "# Calculate the mean of each column (2nd dimension)\n",
    "column_means = np.mean(arr, axis=0)\n",
    "\n",
    "print(column_means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinard_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
