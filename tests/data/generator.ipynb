{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pinard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate preprocessing test data - Snapshot (XX-XX-XX - commit:)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from pinard import preprocessor as pp\n",
    "from pinard.nirs_pipelines import FeatureAugmentation\n",
    "\n",
    "x_fname = 'test_preprocessing_src.csv'\n",
    "x_df = pd.read_csv(x_fname, sep=';', header=None)\n",
    "x = x_df.astype(np.float32).values\n",
    "\n",
    "preprocessing = [   ('Id', pp.IdentityTransformer()),\n",
    "                    ('Baseline', pp.Baseline()),\n",
    "                    ('StandardNormalVariate', pp.StandardNormalVariate()), \n",
    "                    ('RobustNormalVariate', pp.RobustNormalVariate()),\n",
    "                    ('SavitzkyGolay', pp.SavitzkyGolay()),\n",
    "                    ('Normalize', pp.Normalize()),\n",
    "                    ('Detrend', pp.Detrend()),\n",
    "                    ('MultiplicativeScatterCorrection', pp.MultiplicativeScatterCorrection()),\n",
    "                    ('Derivate', pp.Derivate()),\n",
    "                    ('Gaussian', pp.Gaussian(order = 2, sigma = 1)),\n",
    "                    ('Wavelet', pp.Wavelet()),\n",
    "                    ('SimpleScale', pp.SimpleScale()),\n",
    "                ]\n",
    "\n",
    "pipeline = FeatureAugmentation(preprocessing)\n",
    "xt = pipeline.fit_transform(x)\n",
    "xtt = np.swapaxes(xt, 1, 2)\n",
    "a = pp.baseline(x)[0]\n",
    "xtt = np.concatenate(xtt)\n",
    "b = xtt[0:12,:]\n",
    "np.savetxt(\"test_preprocessing_validation.csv\", b, delimiter=\";\")\n",
    "np.savetxt(\"test_data.csv\", x, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pinard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6096/1840290166.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpinard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test_split.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pinard'"
     ]
    }
   ],
   "source": [
    "## Generate model selection test data - Snapshot (XX-XX-XX - commit:)\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from pinard import model_selection\n",
    "\n",
    "x_fname = 'test_split.csv'\n",
    "x_df = pd.read_csv(x_fname, sep=';', header=None)\n",
    "x = x_df.astype(np.float32).values\n",
    "y = np.reshape(x[:,0], (-1,1))\n",
    "x = x[:,1:]\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"random\", test_size=0.25, random_state=42)\n",
    "test_data = train_index\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"k_mean\", test_size=0.25, random_state=42, metric= \"canberra\")\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"k_mean\", test_size=0.25, random_state=42, pca_components=4)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"kennard_stone\", test_size=0.25, random_state=42)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"kennard_stone\", test_size=0.25, random_state=42, metric='correlation', pca_components=8)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, method=\"kennard_stone\", test_size=0.25, random_state=42, metric='correlation')\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"spxy\", test_size=0.25, random_state=42)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"spxy\", test_size=0.25, random_state=42, pca_components=2)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"spxy\", test_size=0.25, random_state=42, metric='canberra')\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"stratified\", test_size=0.25, random_state=42)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"stratified\", test_size=0.25, random_state=42, n_bins=4)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "train_index, test_index = model_selection.train_test_split_idx(x, y=y, method=\"circular\", test_size=0.25, random_state=42)\n",
    "test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "# train_index, test_index = model_selection.train_test_split_idx(x, method=\"SPlit\", test_size=0.25, random_state=42)\n",
    "# test_data = np.column_stack((test_data, train_index))\n",
    "\n",
    "np.savetxt(\"test_split_validation.csv\", test_data.astype(np.int32), delimiter=\";\", fmt='%i')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\ipykernel_launcher.py:5: SyntaxWarning: Minimum of desired feature range should be smaller than maximum.Got 3.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.warn(\n",
    "    \"Minimum of desired feature range should be smaller than maximum. \"\n",
    "    \"Got %s.\" % str(3),\n",
    "    SyntaxWarning,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b09f6e5407ec4329146609a0cb08cbbe4720f97bb26598a93c421b663bd10d2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pynirsENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
