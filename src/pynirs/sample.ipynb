{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'augmenter' has no attribute 'Augmenter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7476/2393008319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# # augmentation definition (default uses all functions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m augmenter = aug.Augmenter([\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'spl_def'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomSplineDeformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'rot_trans'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRotateTranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'augmenter' has no attribute 'Augmenter'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"\") + \"/../src/pynirs\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from nirs_set import NIRS_Set\n",
    "import preprocessor as pp\n",
    "import splitter as sp\n",
    "import augmenter as aug\n",
    "from pipeline_tools import FeatureUnionOnAxis\n",
    "\n",
    "\n",
    "#### MODEL creation\n",
    "def create_model(optimizer = 'adagrad', \n",
    "                 kernel_initializer = 'glorot_uniform', \n",
    "                 dropout = 0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu', kernel_initializer = kernel_initializer))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation = 'sigmoid', kernel_initializer = kernel_initializer))\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#### Data augmenters\n",
    "\n",
    "# # augmentation definition (default uses all functions)\n",
    "augmenter = aug.Augmenter([\n",
    "    ('spl_def', aug.RandomSplineDeformation()), \n",
    "    ('rot_trans', aug.RotateTranslate()), \n",
    "    ('spl_spl', aug.SplineSimplification())\n",
    "    ], keep_classes = True)\n",
    "\n",
    "\n",
    "#### Pipeline transformers\n",
    "\n",
    "# # Order 1 filters stacked\n",
    "filters = FeatureUnionOnAxis([\n",
    "    ('id', pp.IdentityTransformer()), \n",
    "    ('derivate', pp.Derivate()), \n",
    "    ('spl', pp.RobustNormalVariate()), \n",
    "    ('haar', pp.Wavelet())\n",
    "    ], axis = 1)\n",
    "\n",
    "# # Order 2 filters stacked\n",
    "sndfilters = FeatureUnionOnAxis([\n",
    "    ('id', pp.IdentityTransformer()), \n",
    "    ('derivate', pp.Derivate()), \n",
    "    ('spl', pp.RobustNormalVariate()), \n",
    "    ('haar', pp.Wavelet())\n",
    "    ], axis = 1)\n",
    "\n",
    "# # The pipeline with the keras regressor. Can be replaced by any sklearn regressor if\n",
    "# # filters preprocessing is done in 1D (FeatureUnion instead of FeatureUnionOnAxis)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('filters', filters), \n",
    "    ('sndfilters', sndfilters),\n",
    "    # ('pls', PLS())\n",
    "    ('nn', KerasRegressor(build_fn = create_model, verbose = 0))\n",
    "])\n",
    "\n",
    "# ## TransformedTargetRegressor enables the transformation of Y before and after\n",
    "estimator = TransformedTargetRegressor(estimator = pipeline, transformer = StandardScaler())\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "n = NIRS_Set('data')\n",
    "X, y = n.load('Xcal.csv', 'Ycal.csv', x_hdr = 0, y_hdr = 0)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "# ### EXAMPLE 1 > simple fit\n",
    "X_train, X_test, y_train, y_test = sp.sk_train_test_split(X, y)\n",
    "X_train, y_train = augmenter.fit_transform(X_train, y_train)\n",
    "estimator.fit(X_train, y_train)\n",
    "Y_preds = estimator.predict(X_test)\n",
    "print(f1_score(y_test, Y_preds, average = 'micro'))\n",
    "\n",
    "\n",
    "\n",
    "# ### EXAMPLE 2 > Cross Validation no augmentation\n",
    "kf = sp.KFold(method='kennard_stone', n_splits=5)\n",
    "print(cross_validate(estimator, X, y, scoring = 'neg_mean_squared_error', cv = kf))\n",
    "\n",
    "# ### EXAMPLE 3 > Hyperparams\n",
    "param_grid = {\n",
    "    'haar__method':['haar', 'bior1.3'], \n",
    "    'nn__optimizer':['rmsprop', 'adam', 'adagrad'], \n",
    "    'nn__epochs':[4, 8], \n",
    "    'nn__dropout':[0.1, 0.2], \n",
    "    'nn__kernel_initializer':['glorot_uniform', 'normal', 'uniform']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, cv = 3, param_grid = param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a027d9ccaa4161f7bb2a6671f63bb76a78cb94a27161911cf16ac7661ccf92de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pynirsENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
